{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIS DQN 画像入力\n",
    "学習済みネットワークを使わずに画像をQNetworkの入力としている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GYM\n",
    "import sys\n",
    "tmp_path = []\n",
    "for it in sys.path:\n",
    "    if not 'gym' in it:\n",
    "        # print(it)\n",
    "        tmp_path.append(it)\n",
    "sys.path = tmp_path\n",
    "sys.path.append('../..')\n",
    "# faster rcnn\n",
    "import sys\n",
    "sys.path.append('../../../../chainer-faster-rcnn')\n",
    "from lib.cpu_nms import cpu_nms as nms\n",
    "from lib.models.faster_rcnn import FasterRCNN\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import six.moves.cPickle as pickle\n",
    "\n",
    "import gym\n",
    "from PIL import Image\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda, FunctionSet, Variable, optimizers\n",
    "from chainer import links as L\n",
    "import chainer.functions as F\n",
    "from chainer.links import caffe\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QFunction(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_actions):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "        c1 = 32\n",
    "        c2 = 64\n",
    "        c3 = 64\n",
    "        fc_unit = 256*2\n",
    "\n",
    "        super(QFunction, self).__init__(\n",
    "             # the size of the inputs to each layer will be inferred\n",
    "            conv1=L.Convolution2D(4, c1, 8, stride=4, pad=0),\n",
    "            conv2=L.Convolution2D(c1, c2, 4, stride=2, pad=0),\n",
    "            conv3=L.Convolution2D(c2, c2, 4, stride=2, pad=0),\n",
    "            conv4=L.Convolution2D(c2, c3, 3, stride=1, pad=0),\n",
    "            fc1=L.Linear(6400, fc_unit, initialW=initializer),\n",
    "            fc2=L.Linear(fc_unit, n_actions, initialW=initializer),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x/255.\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = F.relu(self.fc1(h))\n",
    "        y = self.fc2(h)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_greedy_action(Q, obs):\n",
    "    xp = Q.xp\n",
    "    obs = xp.expand_dims(xp.asarray(obs, dtype=np.float32), 0)\n",
    "    with chainer.no_backprop_mode():\n",
    "        q = Q(obs).data[0]\n",
    "    return int(xp.argmax(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_clipped_loss(y, t):\n",
    "    # Add an axis because F.huber_loss only accepts arrays with ndim >= 2\n",
    "    y = F.expand_dims(y, axis=-1)\n",
    "    t = F.expand_dims(t, axis=-1)\n",
    "    return F.sum(F.huber_loss(y, t, 1.0)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(Q, target_Q, opt, samples, gamma=0.99, target_type='dqn'): \n",
    "    xp = Q.xp\n",
    "    s = np.ndarray(shape=(minibatch_size, STATE_LENGTH, FRAME_WIDTH, FRAME_HEIGHT), dtype=np.float32)\n",
    "    a = np.asarray([sample[1] for sample in samples], dtype=np.int32)\n",
    "    r = np.asarray([sample[2] for sample in samples], dtype=np.float32)\n",
    "    done = np.asarray([sample[3] for sample in samples], dtype=np.float32)\n",
    "    s_next = np.ndarray(shape=(minibatch_size, STATE_LENGTH, FRAME_WIDTH, FRAME_HEIGHT), dtype=np.float32)\n",
    "\n",
    "    for i in xrange(minibatch_size):\n",
    "        s[i] = samples[i][0]\n",
    "        s_next[i] = samples[i][4]\n",
    "\n",
    "    # to gpu if available\n",
    "    s = xp.asarray(s)\n",
    "    a = xp.asarray(a)\n",
    "    r = xp.asarray(r)\n",
    "    done = xp.asarray(done)\n",
    "    s_next = xp.asarray(s_next)\n",
    "    \n",
    "    # Prediction: Q(s,a)\n",
    "    y = F.select_item(Q(s), a)\n",
    "    # Target: r + gamma * max Q_b (s',b)\n",
    "    with chainer.no_backprop_mode():\n",
    "        if target_type == 'dqn':\n",
    "            t = xp.sign(r) + gamma * (1 - done) * F.max(target_Q(s_next), axis=1)\n",
    "        elif target_type == 'double_dqn':\n",
    "            t = xp.sign(r) + gamma * (1 - done) * F.select_item(\n",
    "                target_Q(s_next), F.argmax(Q(s_next), axis=1))\n",
    "        else:\n",
    "            raise ValueError('Unsupported target_type: {}'.format(target_type))\n",
    "    loss = mean_clipped_loss(y, t)\n",
    "    Q.cleargrads()\n",
    "    loss.backward()\n",
    "    opt.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanQvalue(Q, samples): \n",
    "    xp = Q.xp\n",
    "    s = np.ndarray(shape=(minibatch_size, STATE_LENGTH, FRAME_WIDTH, FRAME_HEIGHT), dtype=np.float32)\n",
    "    a = np.asarray([sample[1] for sample in samples], dtype=np.int32)\n",
    "\n",
    "    for i in xrange(minibatch_size):\n",
    "        s[i] = samples[i][0]\n",
    "\n",
    "    # to gpu if available\n",
    "    s = xp.asarray(s)\n",
    "    a = xp.asarray(a)\n",
    "\n",
    "    # Prediction: Q(s,a)\n",
    "    y = F.select_item(Q(s), a)\n",
    "    mean_Q = (F.sum(y)/minibatch_size).data\n",
    "    return mean_Q\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力画像をStateへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_LENGTH = 4  # Number of most recent frames to produce the input to the network\n",
    "FRAME_WIDTH = 224  # Resized frame width\n",
    "FRAME_HEIGHT = 224  # Resized frame height\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "class ObsProcesser:\n",
    "    mean_file = 'ilsvrc_2012_mean.npy'\n",
    "    mean_name, ext = os.path.splitext(mean_file)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "            \n",
    "    def init_state(self, obs):\n",
    "        processed_obs = self._preprocess_observation(obs)\n",
    "        state = [processed_obs for _ in xrange(STATE_LENGTH)]\n",
    "        self.state = np.stack(state, axis=0)\n",
    "        \n",
    "    def obs2state(self, obs):\n",
    "        processed_obs = self._preprocess_observation(obs)\n",
    "        self.state = np.concatenate((self.state[1:, :, :], processed_obs[np.newaxis]), axis=0)\n",
    "        return self.state\n",
    "    \n",
    "    def _preprocess_observation(self, obs):\n",
    "        img = np.array(obs[\"image\"][0])\n",
    "        preprossed = np.asarray(resize(rgb2gray(img), (FRAME_WIDTH, FRAME_HEIGHT))*255, dtype=np.uint8)\n",
    "        return preprossed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obs2image(obs):\n",
    "    return np.array(obs['image'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロボットから情報から椅子の世界座標系の位置（x, z）を求める\n",
    "## カメラの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_IMAGE_HEIGTH = 224\n",
    "INPUT_IMAGE_WIDTH = 224\n",
    "\n",
    "EYE_HEIGHT = 1.12\n",
    "EYE_FOV = np.pi/2\n",
    "FOCUS_LENGTH = INPUT_IMAGE_HEIGTH/(2*np.tan(EYE_FOV/2))\n",
    "\n",
    "#どれくらいずれていても椅子とみなすか [m]\n",
    "CHAIR_TH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimateChairPosition(x1, y1, x2, y2, info):\n",
    "    # 椅子検知した四角の下辺中央の座標\n",
    "    xb=x1+(x2-x1)/2\n",
    "    if y2 < INPUT_IMAGE_HEIGTH/2:\n",
    "        print('not chair')\n",
    "        return\n",
    "    # 左下原点のimage座標系へ変換\n",
    "    image_pos = np.array([xb, INPUT_IMAGE_HEIGTH - y2])\n",
    "    \n",
    "    # 画像上の中心からの距離\n",
    "    diff_pos = image_pos - np.array([INPUT_IMAGE_HEIGTH/2, INPUT_IMAGE_WIDTH/2])\n",
    "    # 光線ベクトルへ\n",
    "    ray = np.append(diff_pos, FOCUS_LENGTH)\n",
    "    ray = ray / np.linalg.norm(ray)  \n",
    "    # 光線ベクトルと地面との交点を算出\n",
    "    if ray[1] > 0:\n",
    "        print('not chair')\n",
    "        return \n",
    "    scale = EYE_HEIGHT/(-ray[1])\n",
    "    chair_from_agent = scale*ray[[0,2]]\n",
    "    \n",
    "    # Agentの情報\n",
    "    agent_pos = info['agent_info']['pos'][[0,2]]\n",
    "    agent_angle = np.deg2rad(info['agent_info']['angle'][1])\n",
    "    # Rotation\n",
    "    R = np.array([[np.cos(-agent_angle), -np.sin(-agent_angle)],\n",
    "                  [np.sin(-agent_angle), np.cos(-agent_angle)]])\n",
    "    # 世界座標系からみた椅子の位置\n",
    "    chair_pos = agent_pos + np.dot(R, chair_from_agent)\n",
    "    return chair_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 椅子検知器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChairDetector():\n",
    "    CLASSES = ('__background__',\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "    CHAIR_ID = 9\n",
    "    PIXEL_MEANS = np.array([[[102.9801, 115.9465, 122.7717]]])\n",
    "\n",
    "    def __init__(self, gpu=-1):\n",
    "        pickle_file = 'data/VGG16_faster_rcnn_final.pickle'\n",
    "        if os.path.exists(pickle_file):\n",
    "            print(\"loading... \" + pickle_file),\n",
    "            self.model = pickle.load(open(pickle_file))\n",
    "            print(\"done\")\n",
    "        else:\n",
    "            self.model = FasterRCNN(gpu)\n",
    "            serializers.load_npz('data/VGG16_faster_rcnn_final.model', self.model)\n",
    "            pickle.dump(self.model, open(pickle_file, 'wb'),-1)\n",
    "            print(\"pickle.dump finished\")\n",
    "        \n",
    "        self.model.train = False\n",
    "        if chainer.cuda.available and gpu >= 0:\n",
    "            self.model.to_gpu(gpu)\n",
    "        self.gpu = gpu\n",
    "        \n",
    "    def forward(self, orig_image):\n",
    "        img, im_scale = self.img_preprocessing(orig_image, self.PIXEL_MEANS)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        if self.gpu >= 0:\n",
    "            img = cuda.to_gpu(img, device=self.gpu)\n",
    "        img = chainer.Variable(img, volatile=True)\n",
    "        h, w = img.data.shape[2:]\n",
    "        cls_score, bbox_pred = self.model(img, np.array([[h, w, im_scale]]))\n",
    "        cls_score = cls_score.data\n",
    "        return cls_score, bbox_pred, im_scale\n",
    "\n",
    "    def img_preprocessing(self, orig_img, pixel_means, max_size=1000, scale=600):\n",
    "        img = orig_img.astype(np.float32, copy=True)\n",
    "        img -= pixel_means\n",
    "        im_size_min = np.min(img.shape[0:2])\n",
    "        im_size_max = np.max(img.shape[0:2])\n",
    "        im_scale = float(scale) / float(im_size_min)\n",
    "        if np.round(im_scale * im_size_max) > max_size:\n",
    "            im_scale = float(max_size) / float(im_size_max)\n",
    "        img = cv.resize(img, None, None, fx=im_scale, fy=im_scale,\n",
    "                        interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "        return img.transpose([2, 0, 1]).astype(np.float32), im_scale\n",
    "\n",
    "\n",
    "    def detect_chair_bbox(self, img, nms_thresh=0.3, conf=0.8):\n",
    "        cls_score, bbox_pred, im_scale = self.forward(img)\n",
    "        if self.gpu >= 0:\n",
    "            self.clss = chainer.cuda.cupy.asnumpy(cls_score)\n",
    "            self.bbox = chainer.cuda.cupy.asnumpy(bbox_pred)\n",
    "        \n",
    "        CV_AA = 16\n",
    "        fontScale = 0.8\n",
    "        \n",
    "        cls_id = self.CHAIR_ID\n",
    "        _cls = self.clss[:, cls_id][:, np.newaxis]\n",
    "        _bbx = self.bbox[:, cls_id * 4: (cls_id + 1) * 4]\n",
    "        dets = np.hstack((_bbx, _cls))\n",
    "        keep = nms(dets, nms_thresh)\n",
    "        dets = dets[keep, :]\n",
    "\n",
    "        inds = np.where(dets[:, -1] >= conf)[0]\n",
    "        chair_bbox = []\n",
    "        for i in inds:\n",
    "            x1, y1, x2, y2 = map(int, dets[i, :4])\n",
    "            chair_bbox.append((x1, y1, x2, y2))\n",
    "        return chair_bbox\n",
    " \n",
    "    def calculate_reward(self, obs, info):\n",
    "        self.input_image = obs2image(obs)\n",
    "        chair_bbox = self.detect_chair_bbox(self.input_image)\n",
    "\n",
    "        chair_positions = []\n",
    "        for x1, y1, x2, y2 in chair_bbox:\n",
    "            pos = estimateChairPosition(x1, y1, x2, y2, info)\n",
    "            if pos is not None:\n",
    "                chair_positions.append(pos)\n",
    "                # print('detect chair position : {}'.format(pos))\n",
    "\n",
    "        groudtruth_chair_pos = np.array([it[[0,2]] for it in info['obj_info']['pos']])\n",
    "\n",
    "        chair_ids = []\n",
    "        for estimate in chair_positions:\n",
    "            # 距離の測定\n",
    "            diff = np.linalg.norm(groudtruth_chair_pos - estimate, axis=1)\n",
    "            tmp_index = np.argmin(diff)\n",
    "            # 閾値以下だったら認識が正しい\n",
    "            if diff[tmp_index] < CHAIR_TH:\n",
    "                chair_ids.append(int(info['obj_info']['id'][tmp_index]))\n",
    "                #print('chair id {}:{}'.format(chair_ids[-1], estimate))\n",
    "        \n",
    "        return len(chair_ids), chair_ids\n",
    "    \n",
    "    def draw_result(self, img, nms_thresh=0.3, conf=0.8):\n",
    "        cls_score, bbox_pred, im_scale = self.forward(img)\n",
    "        if self.gpu >= 0:\n",
    "            clss = chainer.cuda.cupy.asnumpy(cls_score)\n",
    "            bbox = chainer.cuda.cupy.asnumpy(bbox_pred)\n",
    "        \n",
    "        CV_AA = 16\n",
    "        fontScale = 0.5\n",
    "        result = img.copy()\n",
    "        for cls_id in range(1, 21):\n",
    "            _cls = clss[:, cls_id][:, np.newaxis]\n",
    "            _bbx = bbox[:, cls_id * 4: (cls_id + 1) * 4]\n",
    "            dets = np.hstack((_bbx, _cls))\n",
    "            keep = nms(dets, nms_thresh)\n",
    "            dets = dets[keep, :]\n",
    "\n",
    "            inds = np.where(dets[:, -1] >= conf)[0]\n",
    "            for i in inds:\n",
    "                x1, y1, x2, y2 = map(int, dets[i, :4])\n",
    "                cv.rectangle(result, (x1, y1), (x2, y2), (0, 0, 255), 2, CV_AA)\n",
    "                disp_text = \"{0}:{1:.3f}\".format(self.CLASSES[cls_id], dets[i, 4])\n",
    "                ret, baseline = cv.getTextSize( disp_text, cv.FONT_HERSHEY_SIMPLEX, fontScale, 1)\n",
    "                cv.rectangle(result, (x1, y2 - ret[1] - baseline),\n",
    "                             (x1 + ret[0], y2), (0, 0, 255), -1)\n",
    "                cv.putText(result, disp_text, (x1, y2 - baseline),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, fontScale, (255, 255, 255), 1, CV_AA)\n",
    "\n",
    "        #result = cv.cvtColor(result, cv.COLOR_BGR2RGB)\n",
    "        return result\n",
    "    \n",
    "    def draw_chair(self, nms_thresh=0.3, conf=0.8):\n",
    "        '''\n",
    "            this function must be called after calculate_reward\n",
    "            self.input_image, self.clss and self.bbox are updated in calculate_reward\n",
    "        '''\n",
    "        CV_AA = 16\n",
    "        fontScale = 0.5\n",
    "        result = self.input_image.copy()\n",
    "        \n",
    "        cls_id = self.CHAIR_ID\n",
    "        _cls = self.clss[:, cls_id][:, np.newaxis]\n",
    "        _bbx = self.bbox[:, cls_id * 4: (cls_id + 1) * 4]\n",
    "        dets = np.hstack((_bbx, _cls))\n",
    "        keep = nms(dets, nms_thresh)\n",
    "        dets = dets[keep, :]\n",
    "\n",
    "        inds = np.where(dets[:, -1] >= conf)[0]\n",
    "        for i in inds:\n",
    "            x1, y1, x2, y2 = map(int, dets[i, :4])\n",
    "            cv.rectangle(result, (x1, y1), (x2, y2), (0, 0, 255), 2, CV_AA)\n",
    "            disp_text = \"{0:.3f}\".format(dets[i, 4])\n",
    "            ret, baseline = cv.getTextSize( disp_text, cv.FONT_HERSHEY_SIMPLEX, fontScale, 1)\n",
    "            cv.rectangle(result, (x1, y2 - ret[1] - baseline),\n",
    "                         (x1 + ret[0], y2), (0, 0, 255), -1)\n",
    "            cv.putText(result, disp_text, (x1, y2 - baseline),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, fontScale, (255, 255, 255), 1, CV_AA)\n",
    "\n",
    "        #result = cv.cvtColor(result, cv.COLOR_BGR2RGB)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadObs():\n",
    "    img = Image.open('chair_image.png')\n",
    "    dep = Image.open('chair_depth.png')\n",
    "\n",
    "    obs={}\n",
    "    obs['image'] = [img]\n",
    "    obs['depth'] = [dep]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveObs(obs):\n",
    "    obs['image'][0].save('chair_image.png')\n",
    "    obs['depth'][0].save('chair_depth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obs = loadObs()\n",
    "# obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saveObs(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lis_DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "depth_image_dim = 224 * 224\n",
    "M = 10000  # number of episodes\n",
    "replay_start_size = 1000  # steps after which we start to update\n",
    "steps_to_decay_epsilon = 100000  # steps to take to decay epsilon\n",
    "min_epsilon = 0.1  # minimum value of epsilon\n",
    "sync_interval = 5000  # interval of target sync\n",
    "evaluation_interval = 100 # 何エピソードごとに評価するか\n",
    "update_inverval = 1\n",
    "minibatch_size = 32  # size of minibatch\n",
    "update_inverval = 1\n",
    "reward_scale = 1  # scale factor for rewards\n",
    "gpu = 0  # gpu id (-1 to use cpu)\n",
    "target_type = 'dqn'  # 'dqn' or 'double_dqn'\n",
    "#NO_OP_MAX = 10 # maximum number of \"do anything\" actions at the start of an episode\n",
    "save_model_inverval = 25000 # interval of save weights\n",
    "save_folder = 'checkpoints'\n",
    "D = collections.deque(maxlen=10 ** 5)  # replay memory: original 10 ** 6\n",
    "\n",
    "Rs = []  # past returns\n",
    "average_Rs = []\n",
    "eval_Rs = [] # evaluation Max reward\n",
    "eval_steps = [] # evaluation Max\n",
    "step = 0  # total steps taken\n",
    "episode = 0\n",
    "\n",
    "networkname = 'image_input'\n",
    "log_file = os.path.join(save_folder,'reward_'+networkname+'.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# disable stderre\n",
    "import os\n",
    "import sys\n",
    "f = open(os.devnull, 'w')\n",
    "sys.stderr = f\n",
    "# 開始の時間表示\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "# save folder\n",
    "if not os.path.isdir(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "# log file\n",
    "with open(log_file, 'w') as the_file:\n",
    "    the_file.write('cycle, episode_reward_sum \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enable_controller = [0,1,2]\n",
    "n_actions = len(enable_controller)\n",
    "obs_processer = ObsProcesser()\n",
    "# \n",
    "chair_detector = ChairDetector(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize chainer models\n",
    "Q = QFunction(n_actions)\n",
    "if gpu >= 0:\n",
    "    chainer.cuda.get_device(gpu).use()\n",
    "    Q.to_gpu(gpu)\n",
    "target_Q = copy.deepcopy(Q)\n",
    "opt = optimizers.RMSpropGraves(lr=0.00025, alpha=0.95, momentum=0.95, eps=0.0001)\n",
    "opt.setup(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_name = 'Lis-v2'\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "\n",
    "obs, _, _, info = env.step(0)\n",
    "obs_processer.init_state(obs)\n",
    "state = obs_processer.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show observation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.array(obs['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.array(obs['depth'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluation(epsilon = 0.05):\n",
    "    Rs_eval = []  # past returns\n",
    "    for episode in range(3):\n",
    "\n",
    "        obs = env.reset()\n",
    "        obs_processer.init_state(obs)\n",
    "        chair_ids = []\n",
    "\n",
    "#         for _ in range(random.randint(1, NO_OP_MAX)):\n",
    "#             a = env.action_space.sample()\n",
    "#             obs, _, _, _ = env.step(a)  # Do anything\n",
    "#             obs_processer.obs2state(obs)\n",
    "            \n",
    "        done = False\n",
    "        R = 0.0\n",
    "        state = obs_processer.state   \n",
    "\n",
    "        while not done:\n",
    "            # Select an action\n",
    "            if np.random.rand() < epsilon:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = get_greedy_action(Q, state)\n",
    "\n",
    "            # Execute an action\n",
    "            new_obs, r, done, _ = env.step(a, chair_ids)\n",
    "\n",
    "            new_state = obs_processer.obs2state(new_obs)\n",
    "            \n",
    "            # 椅子の検知による報酬計算\n",
    "            r, chair_ids = chair_detector.calculate_reward(new_obs, info)\n",
    "            R += r\n",
    "            result_img = chair_detector.draw_chair()\n",
    "            cv.imshow('result', cv.cvtColor(result_img, cv.COLOR_RGB2BGR))\n",
    "            cv.waitKey(1)\n",
    "        \n",
    "            state = new_state           \n",
    "\n",
    "        print('Evaluation : episode: {} step: {} R:{}'.format(episode, step, R))\n",
    "        Rs_eval.append(R)\n",
    "    return Rs_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a figure\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "while episode < M:\n",
    "    obs = env.reset()\n",
    "    obs_processer.init_state(obs)\n",
    "    chair_ids = []\n",
    "\n",
    "#     for _ in range(random.randint(1, NO_OP_MAX)):\n",
    "#         a = env.action_space.sample()\n",
    "#         obs, _, _, _ = env.step(a)  # Do anything\n",
    "#         obs_processer.obs2state(obs)\n",
    "    done = False\n",
    "    R = 0.0\n",
    "    state = obs_processer.state   \n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        # Select an action\n",
    "        epsilon = 1.0 if len(D) < replay_start_size else \\\n",
    "            max(min_epsilon, np.interp(\n",
    "                step, [replay_start_size, replay_start_size+steps_to_decay_epsilon], [1.0, min_epsilon]))\n",
    "        if np.random.rand() < epsilon:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = get_greedy_action(Q, state)\n",
    "\n",
    "        # Execute an action\n",
    "        new_obs, r, done, info = env.step(a, chair_ids)\n",
    "\n",
    "        new_state = obs_processer.obs2state(new_obs)\n",
    "\n",
    "        # 椅子の検知による報酬計算\n",
    "        r, chair_ids = chair_detector.calculate_reward(new_obs, info)\n",
    "#         if r is not 0:\n",
    "#             print('detect chair reward: {}, {}'.format(r, chair_ids))\n",
    "        R += r\n",
    "        result_img = chair_detector.draw_chair()\n",
    "        cv.imshow('result', cv.cvtColor(result_img, cv.COLOR_RGB2BGR))\n",
    "        cv.waitKey(1)\n",
    "\n",
    "        # Store a transition\n",
    "        D.append((state, a, r * reward_scale, done, new_state))\n",
    "        state = new_state\n",
    "\n",
    "        # Sample a random minibatch of transitions\n",
    "        if len(D) >= replay_start_size:\n",
    "            if step % update_inverval == 0:\n",
    "                samples = random.sample(D, minibatch_size)\n",
    "                update(Q, target_Q, opt, samples, target_type=target_type)\n",
    "\n",
    "            if step % sync_interval == 0:\n",
    "                mean_Q = meanQvalue(Q, samples)\n",
    "                target_Q = copy.deepcopy(Q)\n",
    "                print('target Q update! mean Q value : {}, epsilon:{}'.format(mean_Q, epsilon))\n",
    "\n",
    "            if step % save_model_inverval == 0:\n",
    "                save_model_filename = \"lis_dqn_{}_{}.h5\".format(env_name, step)\n",
    "                save_model_path = os.path.join(save_folder, save_model_filename)\n",
    "                print('save model : {}'.format(save_model_path))\n",
    "                chainer.serializers.save_hdf5(save_model_path, Q)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    with open(log_file, 'a') as the_file:\n",
    "        the_file.write(str(episode) + ',' + str(R) + '\\n')\n",
    "\n",
    "    Rs.append(R)\n",
    "    average_R = np.mean(Rs[-100:])\n",
    "    average_Rs.append(average_R)\n",
    "    if episode % 1 is 0:\n",
    "        print('episode: {} step: {} R:{} average_R:{}'.format(\n",
    "              episode, step, R, average_R))\n",
    "\n",
    "    # evaluation\n",
    "    if (episode+1) % evaluation_interval == 0:\n",
    "        R_eval = Evaluation()\n",
    "        eval_Rs.append(max(R_eval))\n",
    "        eval_steps.append(episode)\n",
    "\n",
    "                \n",
    "    ax.clear()\n",
    "    ax.plot(Rs)\n",
    "    ax.plot(average_Rs)\n",
    "    ax.plot(eval_steps, eval_Rs, \"o\")\n",
    "    fig.canvas.draw()\n",
    "    episode += 1\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
