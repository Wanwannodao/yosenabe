{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIS DQN 特徴量入力\n",
    "画像を学習済みネットワークを通して1次元にした特徴量をQNetworkの入力としている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "tmp_path = []\n",
    "for it in sys.path:\n",
    "    if not 'gym' in it:\n",
    "        # print(it)\n",
    "        tmp_path.append(it)\n",
    "sys.path = tmp_path\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import six.moves.cPickle as pickle\n",
    "\n",
    "import gym\n",
    "from PIL import Image\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda, FunctionSet, Variable, optimizers\n",
    "from chainer import links as L\n",
    "import chainer.functions as F\n",
    "from chainer.links import caffe\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CnnFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnFeatureExtractor:\n",
    "    def __init__(self, gpu, model_file, in_size, mean_file, feature_name):\n",
    "        self.gpu = gpu\n",
    "        self.model_file = model_file\n",
    "        self.mean_file = mean_file\n",
    "        self.feature_name = feature_name\n",
    "        self.in_size = in_size\n",
    "        self.batchsize = 1\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            cuda.check_cuda_available()\n",
    "\n",
    "        print('Loading Caffe model file %s...' % self.model_file, file = sys.stderr)\n",
    "        self.func = caffe.CaffeFunction(self.model_file)\n",
    "        print('Loaded', file=sys.stderr)\n",
    "        if self.gpu >= 0:\n",
    "            cuda.get_device(self.gpu).use()\n",
    "            self.func.to_gpu()\n",
    "\n",
    "        mean_image = np.load(self.mean_file)\n",
    "        self.mean_image = self.crop(mean_image)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        y, = self.func(inputs={'data': x}, outputs=[self.feature_name], train=False)\n",
    "        return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y, = self.func(inputs={'data': x}, outputs=[self.feature_name], train=False)\n",
    "        return F.softmax(y)\n",
    "\n",
    "    def feature(self, camera_image):\n",
    "        x_batch = np.ndarray((self.batchsize, 3, self.in_size, self.in_size), dtype=np.float32)\n",
    "        image = np.asarray(camera_image).transpose(2, 0, 1)[::-1].astype(np.float32)\n",
    "        image = self.crop(image)\n",
    "        image -= self.mean_image\n",
    "\n",
    "        x_batch[0] = image\n",
    "        xp = cuda.cupy if self.gpu >= 0 else np\n",
    "        x_data = xp.asarray(x_batch)\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            x_data=cuda.to_gpu(x_data)\n",
    "\n",
    "        x = chainer.Variable(x_data, volatile=True)\n",
    "        feature = self.predict(x)\n",
    "        feature = feature.data\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            feature = cuda.to_cpu(feature)\n",
    "        feature = self.vec(feature)\n",
    "\n",
    "        return feature * 255.0\n",
    "\n",
    "    def crop(self, image):\n",
    "        #assume image is square\n",
    "        cropwidth = image.shape[1] - self.in_size\n",
    "        start = cropwidth // 2\n",
    "        stop = start + self.in_size\n",
    "        return image[:, start:stop, start:stop].copy()\n",
    "\n",
    "    #vectrization, or mat[:] in MATLAB\n",
    "    def vec(self, mat):\n",
    "        return mat.reshape(mat.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QFunction(chainer.Chain):\n",
    "\n",
    "    def __init__(self, input_dim, n_actions):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "\n",
    "        fc_unit = 256\n",
    "        super(QFunction, self).__init__(\n",
    "            fc1=L.Linear(input_dim, fc_unit),\n",
    "            fc2=L.Linear(fc_unit, n_actions),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = x/255.\n",
    "        h = F.relu(self.fc1(h))\n",
    "        y = self.fc2(h)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_greedy_action(Q, obs):\n",
    "    xp = Q.xp\n",
    "    obs = xp.expand_dims(xp.asarray(obs, dtype=np.float32), 0)\n",
    "    with chainer.no_backprop_mode():\n",
    "        q = Q(obs).data[0]\n",
    "    return int(xp.argmax(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_clipped_loss(y, t):\n",
    "    # Add an axis because F.huber_loss only accepts arrays with ndim >= 2\n",
    "    y = F.expand_dims(y, axis=-1)\n",
    "    t = F.expand_dims(t, axis=-1)\n",
    "    return F.sum(F.huber_loss(y, t, 1.0)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(Q, target_Q, opt, samples, gamma=0.99, target_type='dqn'): \n",
    "    xp = Q.xp\n",
    "    s = np.ndarray(shape=(minibatch_size, q_net_input_dim), dtype=np.float32)\n",
    "    a = np.asarray([sample[1] for sample in samples], dtype=np.int32)\n",
    "    r = np.asarray([sample[2] for sample in samples], dtype=np.float32)\n",
    "    done = np.asarray([sample[3] for sample in samples], dtype=np.float32)\n",
    "    s_next = np.ndarray(shape=(minibatch_size, q_net_input_dim), dtype=np.float32)\n",
    "\n",
    "    for i in xrange(minibatch_size):\n",
    "        s[i] = samples[i][0].flatten()\n",
    "        s_next[i] = samples[i][4].flatten()\n",
    "\n",
    "    # to gpu if available\n",
    "    s = xp.asarray(s)\n",
    "    a = xp.asarray(a)\n",
    "    r = xp.asarray(r)\n",
    "    done = xp.asarray(done)\n",
    "    s_next = xp.asarray(s_next)\n",
    "    \n",
    "    # Prediction: Q(s,a)\n",
    "    y = F.select_item(Q(s), a)\n",
    "    # Target: r + gamma * max Q_b (s',b)\n",
    "    with chainer.no_backprop_mode():\n",
    "        if target_type == 'dqn':\n",
    "            t = xp.sign(r) + gamma * (1 - done) * F.max(target_Q(s_next), axis=1)\n",
    "        elif target_type == 'double_dqn':\n",
    "            t = xp.sign(r) + gamma * (1 - done) * F.select_item(\n",
    "                target_Q(s_next), F.argmax(Q(s_next), axis=1))\n",
    "        else:\n",
    "            raise ValueError('Unsupported target_type: {}'.format(target_type))\n",
    "    loss = mean_clipped_loss(y, t)\n",
    "    Q.cleargrads()\n",
    "    loss.backward()\n",
    "    opt.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanQvalue(Q, samples): \n",
    "    xp = Q.xp\n",
    "    s = np.ndarray(shape=(minibatch_size, q_net_input_dim), dtype=np.float32)\n",
    "    a = np.asarray([sample[1] for sample in samples], dtype=np.int32)\n",
    "\n",
    "    for i in xrange(minibatch_size):\n",
    "        s[i] = samples[i][0].flatten()\n",
    "\n",
    "    # to gpu if available\n",
    "    s = xp.asarray(s)\n",
    "    a = xp.asarray(a)\n",
    "\n",
    "    # Prediction: Q(s,a)\n",
    "    y = F.select_item(Q(s), a)\n",
    "    mean_Q = (F.sum(y)/minibatch_size).data\n",
    "    return mean_Q\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力画像をStateへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_LENGTH = 6  # Number of most recent frames to produce the input to the network\n",
    "\n",
    "class ObsProcesser:\n",
    "    mean_file = 'ilsvrc_2012_mean.npy'\n",
    "    mean_name, ext = os.path.splitext(mean_file)\n",
    "\n",
    "    def __init__(self, networkname='googlenet'):\n",
    "        self.state = None\n",
    "\n",
    "        if networkname is 'googlenet':\n",
    "            #GoogLeNet\n",
    "            self.in_size = 224\n",
    "            self.model_file = 'bvlc_googlenet.caffemodel'\n",
    "            self.feature_name = 'pool5/7x7_s1' #aka loss3/fc\n",
    "            \n",
    "        elif networkname is 'alexnet':\n",
    "            #AlexNet\n",
    "            self.in_size = 227\n",
    "            self.model_file = 'bvlc_alexnet.caffemodel'\n",
    "            self.feature_name = 'pool5'\n",
    "        else:\n",
    "            print('unknown networkn name')\n",
    "\n",
    "        model_name, ext = os.path.splitext(self.model_file)\n",
    "        self.cnn_feature_extractor = model_name + '.' + self.mean_name + '.' + self.feature_name + '.extractor.pickle'\n",
    "        self.cnn_feature_extractor = self.cnn_feature_extractor.replace('/', '_')\n",
    "        \n",
    "        if os.path.exists(self.cnn_feature_extractor):\n",
    "            print(\"loading... \" + self.cnn_feature_extractor),\n",
    "            self.feature_extractor = pickle.load(open(self.cnn_feature_extractor))\n",
    "            print(\"done\")\n",
    "        else:\n",
    "            self.feature_extractor = CnnFeatureExtractor(self.use_gpu,\n",
    "                self.model_file, self.in_size, self.mean_file, self.feature_name)\n",
    "            pickle.dump(self.feature_extractor, open(self.cnn_feature_extractor, 'wb'),-1)\n",
    "            print(\"pickle.dump finished\")\n",
    "            \n",
    "    def init_state(self, obs):\n",
    "        processed_obs = self._preprocess_observation(obs)\n",
    "        state = [processed_obs for _ in xrange(STATE_LENGTH)]\n",
    "        self.state = np.stack(state, axis=0)\n",
    "        \n",
    "    def obs2state(self, obs):\n",
    "        processed_obs = self._preprocess_observation(obs)\n",
    "        self.state = np.concatenate((self.state[1:, :], processed_obs[np.newaxis]), axis=0)\n",
    "        return self.state\n",
    "    \n",
    "    def _preprocess_observation(self, obs):\n",
    "        preprossed = np.r_[self.feature_extractor.feature(obs[\"image\"][0]),\n",
    "                           obs[\"depth\"][0]/255.]\n",
    "        return preprossed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lis_DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "depth_image_dim = 32 * 32\n",
    "STATE_LENGTH = 4  # Number of most recent frames to produce the input to the network\n",
    "M = 10000  # number of episodes\n",
    "replay_start_size = 1000  # steps after which we start to update\n",
    "steps_to_decay_epsilon = 100000  # steps to take to decay epsilon\n",
    "min_epsilon = 0.1  # minimum value of epsilon\n",
    "sync_interval = 5000  # interval of target sync\n",
    "evaluation_interval = 50 # 何エピソードごとに評価するか\n",
    "update_inverval = 1\n",
    "minibatch_size = 32  # size of minibatch\n",
    "update_inverval = 1\n",
    "reward_scale = 1  # scale factor for rewards\n",
    "gpu = 0  # gpu id (-1 to use cpu)\n",
    "target_type = 'dqn'  # 'dqn' or 'double_dqn'\n",
    "NO_OP_MAX = 10 # maximum number of \"do anything\" actions at the start of an episode\n",
    "save_model_inverval = 25000 # interval of save weights\n",
    "D = collections.deque(maxlen=10 ** 5)  # replay memory: original 10 ** 6\n",
    "\n",
    "Rs = []  # past returns\n",
    "average_Rs = []\n",
    "eval_Rs = [] # evaluation Max reward\n",
    "eval_steps = [] # evaluation Max\n",
    "step = 0  # total steps taken\n",
    "episode = 0\n",
    "\n",
    "networkname = 'googlenet'\n",
    "obs_processer = ObsProcesser(networkname)\n",
    "log_file = 'reward_'+networkname+'.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One-time FF to get the feature length\n",
    "image = Image.new(\"RGB\", (256, 256)) # dummy image\n",
    "image_feature_dim = obs_processer.feature_extractor.feature(image).size\n",
    "q_net_input_dim = (image_feature_dim + depth_image_dim)*STATE_LENGTH\n",
    "enable_controller = [0,1,2]\n",
    "n_actions = len(enable_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize chainer models\n",
    "Q = QFunction(q_net_input_dim, n_actions)\n",
    "if gpu >= 0:\n",
    "    chainer.cuda.get_device(gpu).use()\n",
    "    Q.to_gpu(gpu)\n",
    "target_Q = copy.deepcopy(Q)\n",
    "opt = optimizers.RMSpropGraves(lr=0.00025, alpha=0.95, momentum=0.95, eps=0.0001)\n",
    "opt.setup(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# disable stderre\n",
    "import os\n",
    "import sys\n",
    "f = open(os.devnull, 'w')\n",
    "sys.stderr = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_name = 'Lis-v2'\n",
    "env = gym.make(env_name)\n",
    "obs = env.reset()\n",
    "obs_processer.init_state(obs)\n",
    "state = obs_processer.state\n",
    "# 開始の時間表示\n",
    "from datetime import datetime\n",
    "datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "with open(log_file, 'w') as the_file:\n",
    "    the_file.write('cycle, episode_reward_sum \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show observation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.array(obs['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(obs['depth'][0].reshape(32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluation(epsilon = 0.05):\n",
    "    Rs_eval = []  # past returns\n",
    "    for episode in range(3):\n",
    "\n",
    "        obs = env.reset()\n",
    "        obs_processer.init_state(obs)\n",
    "\n",
    "        for _ in range(random.randint(1, NO_OP_MAX)):\n",
    "            a = env.action_space.sample()\n",
    "            obs, _, _, _ = env.step(a)  # Do anything\n",
    "            obs_processer.obs2state(obs)\n",
    "            \n",
    "        done = False\n",
    "        R = 0.0\n",
    "        state = obs_processer.state   \n",
    "\n",
    "        while not done:\n",
    "            # Select an action\n",
    "            if np.random.rand() < epsilon:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = get_greedy_action(Q, state)\n",
    "\n",
    "            # Execute an action\n",
    "            new_obs, r, done, _ = env.step(a)\n",
    "\n",
    "            new_state = obs_processer.obs2state(new_obs)\n",
    "            R += r\n",
    "            state = new_state           \n",
    "\n",
    "        print('Evaluation : episode: {} step: {} R:{}'.format(episode, step, R))\n",
    "        Rs_eval.append(R)\n",
    "    return Rs_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a figure\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "while episode < M:\n",
    "    obs = env.reset()\n",
    "    obs_processer.init_state(obs)\n",
    "\n",
    "    for _ in range(random.randint(1, NO_OP_MAX)):\n",
    "        a = env.action_space.sample()\n",
    "        obs, _, _, _ = env.step(a)  # Do anything\n",
    "        obs_processer.obs2state(obs)\n",
    "    done = False\n",
    "    R = 0.0\n",
    "    state = obs_processer.state   \n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        # Select an action\n",
    "        epsilon = 1.0 if len(D) < replay_start_size else \\\n",
    "            max(min_epsilon, np.interp(\n",
    "                step, [replay_start_size, replay_start_size+steps_to_decay_epsilon], [1.0, min_epsilon]))\n",
    "        if np.random.rand() < epsilon:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = get_greedy_action(Q, state)\n",
    "\n",
    "        # Execute an action\n",
    "        new_obs, r, done, _ = env.step(a)\n",
    "\n",
    "        new_state = obs_processer.obs2state(new_obs)\n",
    "\n",
    "        R += r\n",
    "\n",
    "        # Store a transition\n",
    "        D.append((state, a, r * reward_scale, done, new_state))\n",
    "        state = new_state\n",
    "\n",
    "        # Sample a random minibatch of transitions\n",
    "        if len(D) >= replay_start_size:\n",
    "            if step % update_inverval == 0:\n",
    "                samples = random.sample(D, minibatch_size)\n",
    "                update(Q, target_Q, opt, samples, target_type=target_type)\n",
    "\n",
    "            if step % sync_interval == 0:\n",
    "                mean_Q = meanQvalue(Q, samples)\n",
    "                target_Q = copy.deepcopy(Q)\n",
    "                print('target Q update! mean Q value : {}, epsilon:{}'.format(mean_Q, epsilon))\n",
    "\n",
    "            if step % save_model_inverval == 0:\n",
    "                save_model_filename = \"lis_dqn_{}_{}.h5\".format(env_name, step)\n",
    "                print('save model : {}'.format(save_model_filename))\n",
    "                chainer.serializers.save_hdf5(save_model_filename, Q)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    with open(log_file, 'a') as the_file:\n",
    "        the_file.write(str(episode) + ',' + str(R) + '\\n')\n",
    "\n",
    "    Rs.append(R)\n",
    "    average_R = np.mean(Rs[-50:])\n",
    "    average_Rs.append(average_R)\n",
    "    if episode % 1 is 0:\n",
    "        print('episode: {} step: {} R:{} average_R:{}'.format(\n",
    "              episode, step, R, average_R))\n",
    "\n",
    "    # evaluation\n",
    "    if (episode+1) % evaluation_interval == 0:\n",
    "        R_eval = Evaluation()\n",
    "        eval_Rs.append(max(R_eval))\n",
    "        eval_steps.append(episode)\n",
    "\n",
    "                \n",
    "    ax.clear()\n",
    "    ax.plot(Rs)\n",
    "    ax.plot(average_Rs)\n",
    "    ax.plot(eval_steps, eval_Rs, \"o\")\n",
    "    fig.canvas.draw()\n",
    "    episode += 1\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
