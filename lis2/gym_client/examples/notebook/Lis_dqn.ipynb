{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "tmp_path = []\n",
    "for it in sys.path:\n",
    "    if not 'gym' in it:\n",
    "        # print(it)\n",
    "        tmp_path.append(it)\n",
    "sys.path = tmp_path\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CnnDqnAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import six.moves.cPickle as pickle\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from chainer import cuda\n",
    "\n",
    "class CnnDqnAgent(object):\n",
    "    policy_frozen = False\n",
    "    epsilon_delta = 1.0 / 10 ** 4.4\n",
    "    min_eps = 0.1\n",
    "\n",
    "    actions = [0, 1, 2]\n",
    "\n",
    "    cnn_feature_extractor = 'alexnet_feature_extractor.pickle'\n",
    "    model = 'bvlc_alexnet.caffemodel'\n",
    "    model_type = 'alexnet'\n",
    "    image_feature_dim = 256 * 6 * 6\n",
    "    image_feature_count = 1\n",
    "\n",
    "    def _observation_to_featurevec(self, observation):\n",
    "        # TODO clean\n",
    "        if self.image_feature_count == 1:\n",
    "            return np.r_[self.feature_extractor.feature(observation[\"image\"][0]),\n",
    "                         observation[\"depth\"][0]]\n",
    "        elif self.image_feature_count == 4:\n",
    "            return np.r_[self.feature_extractor.feature(observation[\"image\"][0]),\n",
    "                         self.feature_extractor.feature(observation[\"image\"][1]),\n",
    "                         self.feature_extractor.feature(observation[\"image\"][2]),\n",
    "                         self.feature_extractor.feature(observation[\"image\"][3]),\n",
    "                         observation[\"depth\"][0],\n",
    "                         observation[\"depth\"][1],\n",
    "                         observation[\"depth\"][2],\n",
    "                         observation[\"depth\"][3]]\n",
    "        else:\n",
    "            print(\"not supported: number of camera\")\n",
    "\n",
    "    def agent_init(self, **options):\n",
    "        self.use_gpu = options['use_gpu']\n",
    "        self.depth_image_dim = options['depth_image_dim']\n",
    "        self.q_net_input_dim = self.image_feature_dim * self.image_feature_count + self.depth_image_dim\n",
    "\n",
    "        if os.path.exists(self.cnn_feature_extractor):\n",
    "            print(\"loading... \" + self.cnn_feature_extractor)\n",
    "            self.feature_extractor = pickle.load(open(self.cnn_feature_extractor))\n",
    "            print(\"done\")\n",
    "        else:\n",
    "            self.feature_extractor = CnnFeatureExtractor(self.use_gpu, self.model, self.model_type, self.image_feature_dim)\n",
    "            pickle.dump(self.feature_extractor, open(self.cnn_feature_extractor, 'wb'),-1)\n",
    "            print(\"pickle.dump finished\")\n",
    "\n",
    "        self.time = 0\n",
    "        self.epsilon = 1.0  # Initial exploratoin rate\n",
    "        self.q_net = QNet(self.use_gpu, self.actions, self.q_net_input_dim)\n",
    "\n",
    "    def agent_start(self, observation):\n",
    "        obs_array = self._observation_to_featurevec(observation)\n",
    "\n",
    "        # Initialize State\n",
    "        self.state = np.zeros((self.q_net.hist_size, self.q_net_input_dim), dtype=np.uint8)\n",
    "        self.state[0] = obs_array\n",
    "        state_ = np.asanyarray(self.state.reshape(1, self.q_net.hist_size, self.q_net_input_dim), dtype=np.float32)\n",
    "        if self.use_gpu >= 0:\n",
    "            state_ = cuda.to_gpu(state_)\n",
    "\n",
    "        # Generate an Action e-greedy\n",
    "        action, q_now = self.q_net.e_greedy(state_, self.epsilon)\n",
    "        return_action = action\n",
    "\n",
    "        # Update for next step\n",
    "        self.last_action = copy.deepcopy(return_action)\n",
    "        self.last_state = self.state.copy()\n",
    "        self.last_observation = obs_array\n",
    "\n",
    "        return return_action\n",
    "\n",
    "    def agent_step(self, reward, observation):\n",
    "        obs_array = self._observation_to_featurevec(observation)\n",
    "\n",
    "        #obs_processed = np.maximum(obs_array, self.last_observation)  # Take maximum from two frames\n",
    "\n",
    "        # Compose State : 4-step sequential observation\n",
    "        if self.q_net.hist_size == 4:\n",
    "            self.state = np.asanyarray([self.state[1], self.state[2], self.state[3], obs_array], dtype=np.uint8)\n",
    "        elif self.q_net.hist_size == 2:\n",
    "            self.state = np.asanyarray([self.state[1], obs_array], dtype=np.uint8)\n",
    "        elif self.q_net.hist_size == 1:\n",
    "            self.state = np.asanyarray([obs_array], dtype=np.uint8)\n",
    "        else:\n",
    "            print(\"self.DQN.hist_size err\")\n",
    "\n",
    "        state_ = np.asanyarray(self.state.reshape(1, self.q_net.hist_size, self.q_net_input_dim), dtype=np.float32)\n",
    "        if self.use_gpu >= 0:\n",
    "            state_ = cuda.to_gpu(state_)\n",
    "\n",
    "        # Exploration decays along the time sequence\n",
    "        if self.policy_frozen is False:  # Learning ON/OFF\n",
    "            if self.q_net.initial_exploration < self.time:\n",
    "                self.epsilon -= self.epsilon_delta\n",
    "                if self.epsilon < self.min_eps:\n",
    "                    self.epsilon = self.min_eps\n",
    "                eps = self.epsilon\n",
    "            else:  # Initial Exploation Phase\n",
    "                print(\"Initial Exploration : %d/%d steps\" % (self.time, self.q_net.initial_exploration)),\n",
    "                eps = 1.0\n",
    "        else:  # Evaluation\n",
    "            print(\"Policy is Frozen\")\n",
    "            eps = 0.05\n",
    "\n",
    "        # Generate an Action by e-greedy action selection\n",
    "        action, q_now = self.q_net.e_greedy(state_, eps)\n",
    "\n",
    "        return action, eps, q_now, obs_array\n",
    "\n",
    "    def agent_step_update(self, reward, action, eps, q_now, obs_array):\n",
    "        # Learning Phase\n",
    "        if self.policy_frozen is False:  # Learning ON/OFF\n",
    "            self.q_net.stock_experience(self.time, self.last_state, self.last_action, reward, self.state, False)\n",
    "            self.q_net.experience_replay(self.time)\n",
    "\n",
    "        # Target model update\n",
    "        if self.q_net.initial_exploration < self.time and np.mod(self.time, self.q_net.target_model_update_freq) == 0:\n",
    "            print(\"Model Updated\")\n",
    "            self.q_net.target_model_update()\n",
    "\n",
    "        # Simple text based visualization\n",
    "        if self.use_gpu >= 0:\n",
    "            q_max = np.max(q_now.get())\n",
    "        else:\n",
    "            q_max = np.max(q_now)\n",
    "\n",
    "        print('Step:%d  Action:%d  Reward:%.1f  Epsilon:%.6f  Q_max:%3f' % (\n",
    "            self.time, self.q_net.action_to_index(action), reward, eps, q_max))\n",
    "\n",
    "        # Updates for next step\n",
    "        self.last_observation = obs_array\n",
    "\n",
    "        if self.policy_frozen is False:\n",
    "            self.last_action = copy.deepcopy(action)\n",
    "            self.last_state = self.state.copy()\n",
    "            self.time += 1\n",
    "\n",
    "    def agent_end(self, reward):  # Episode Terminated\n",
    "        print('episode finished. Reward:%.1f / Epsilon:%.6f' % (reward, self.epsilon))\n",
    "\n",
    "        # Learning Phase\n",
    "        if self.policy_frozen is False:  # Learning ON/OFF\n",
    "            self.q_net.stock_experience(self.time, self.last_state, self.last_action, reward, self.last_state,\n",
    "                                        True)\n",
    "            self.q_net.experience_replay(self.time)\n",
    "\n",
    "        # Target model update\n",
    "        if self.q_net.initial_exploration < self.time and np.mod(self.time, self.q_net.target_model_update_freq) == 0:\n",
    "            print(\"Model Updated\")\n",
    "            self.q_net.target_model_update()\n",
    "\n",
    "        # Time count\n",
    "        if self.policy_frozen is False:\n",
    "            self.time += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CnnFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "from chainer.links import caffe\n",
    "\n",
    "\n",
    "class CnnFeatureExtractor:\n",
    "    def __init__(self, gpu, model, model_type, out_dim):\n",
    "        self.gpu = gpu\n",
    "        self.model = 'bvlc_alexnet.caffemodel'\n",
    "        self.model_type = 'alexnet'\n",
    "        self.batchsize = 1\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            cuda.check_cuda_available()\n",
    "\n",
    "        print('Loading Caffe model file %s...' % self.model, file = sys.stderr)\n",
    "        self.func = caffe.CaffeFunction(self.model)\n",
    "        print('Loaded', file=sys.stderr)\n",
    "        if self.gpu >= 0:\n",
    "            cuda.get_device(self.gpu).use()\n",
    "            self.func.to_gpu()\n",
    "\n",
    "        if self.model_type == 'alexnet':\n",
    "            self.in_size = 227\n",
    "            mean_image = np.load('ilsvrc_2012_mean.npy')\n",
    "            del self.func.layers[15:23]\n",
    "            self.outname = 'pool5'\n",
    "            #del self.func.layers[13:23]\n",
    "            #self.outname = 'conv5'\n",
    "\n",
    "            \n",
    "        cropwidth = 256 - self.in_size\n",
    "        start = cropwidth // 2\n",
    "        stop = start + self.in_size\n",
    "        self.mean_image = mean_image[:, start:stop, start:stop].copy()\n",
    "                \n",
    "    def predict(self, x):\n",
    "        y, = self.func(inputs={'data': x}, outputs=[self.outname], train=False)\n",
    "        return y\n",
    "\n",
    "    def feature(self, camera_image):\n",
    "        x_batch = np.ndarray((self.batchsize, 3, self.in_size, self.in_size), dtype=np.float32)\n",
    "        image = np.asarray(camera_image).transpose(2, 0, 1)[::-1].astype(np.float32)\n",
    "        image -= self.mean_image\n",
    "\n",
    "        x_batch[0] = image\n",
    "        xp = cuda.cupy if self.gpu >= 0 else np\n",
    "        x_data = xp.asarray(x_batch)\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            x_data=cuda.to_gpu(x_data)\n",
    "        \n",
    "        x = chainer.Variable(x_data, volatile=True)\n",
    "        feature = self.predict(x)\n",
    "\n",
    "        if self.gpu >= 0:\n",
    "            feature = cuda.to_cpu(feature.data)\n",
    "            feature = feature.reshape(self.out_dim)\n",
    "        else:\n",
    "            feature = feature.data.reshape(self.out_dim)\n",
    "\n",
    "        return feature * 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from chainer import cuda, FunctionSet, Variable, optimizers\n",
    "import chainer.functions as F\n",
    "\n",
    "\n",
    "class QNet:\n",
    "    # Hyper-Parameters\n",
    "    gamma = 0.99  # Discount factor\n",
    "    initial_exploration = 10**3  # Initial exploratoin. original: 5x10^4\n",
    "    replay_size = 32  # Replay (batch) size\n",
    "    target_model_update_freq = 10**4  # Target update frequancy. original: 10^4\n",
    "    data_size = 10**5  # Data size of history. original: 10^6\n",
    "    hist_size = 1 #original: 4\n",
    "\n",
    "    def __init__(self, use_gpu, enable_controller, dim):\n",
    "        self.use_gpu = use_gpu\n",
    "        self.num_of_actions = len(enable_controller)\n",
    "        self.enable_controller = enable_controller\n",
    "        self.dim = dim\n",
    "\n",
    "        print(\"Initializing Q-Network...\")\n",
    "\n",
    "        hidden_dim = 256\n",
    "        self.model = FunctionSet(\n",
    "            l4=F.Linear(self.dim*self.hist_size, hidden_dim, wscale=np.sqrt(2)),\n",
    "            q_value=F.Linear(hidden_dim, self.num_of_actions,\n",
    "                             initialW=np.zeros((self.num_of_actions, hidden_dim),\n",
    "                                               dtype=np.float32))\n",
    "        )\n",
    "        if self.use_gpu >= 0:\n",
    "            self.model.to_gpu()\n",
    "\n",
    "        self.model_target = copy.deepcopy(self.model)\n",
    "\n",
    "        self.optimizer = optimizers.RMSpropGraves(lr=0.00025, alpha=0.95, momentum=0.95, eps=0.0001)\n",
    "        self.optimizer.setup(self.model.collect_parameters())\n",
    "\n",
    "        # History Data :  D=[s, a, r, s_dash, end_episode_flag]\n",
    "        self.d = [np.zeros((self.data_size, self.hist_size, self.dim), dtype=np.uint8),\n",
    "                  np.zeros(self.data_size, dtype=np.uint8),\n",
    "                  np.zeros((self.data_size, 1), dtype=np.int8),\n",
    "                  np.zeros((self.data_size, self.hist_size, self.dim), dtype=np.uint8),\n",
    "                  np.zeros((self.data_size, 1), dtype=np.bool)]\n",
    "\n",
    "    def forward(self, state, action, reward, state_dash, episode_end):\n",
    "        num_of_batch = state.shape[0]\n",
    "        s = Variable(state)\n",
    "        s_dash = Variable(state_dash)\n",
    "\n",
    "        q = self.q_func(s)  # Get Q-value\n",
    "\n",
    "        # Generate Target Signals\n",
    "        tmp = self.q_func_target(s_dash)  # Q(s',*)\n",
    "        if self.use_gpu >= 0:\n",
    "            tmp = list(map(np.max, tmp.data.get()))  # max_a Q(s',a)\n",
    "        else:\n",
    "            tmp = list(map(np.max, tmp.data))  # max_a Q(s',a)\n",
    "\n",
    "        max_q_dash = np.asanyarray(tmp, dtype=np.float32)\n",
    "        if self.use_gpu >= 0:\n",
    "            target = np.asanyarray(q.data.get(), dtype=np.float32)\n",
    "        else:\n",
    "            # make new array\n",
    "            target = np.array(q.data, dtype=np.float32)\n",
    "\n",
    "        for i in xrange(num_of_batch):\n",
    "            if not episode_end[i][0]:\n",
    "                tmp_ = reward[i] + self.gamma * max_q_dash[i]\n",
    "            else:\n",
    "                tmp_ = reward[i]\n",
    "\n",
    "            action_index = self.action_to_index(action[i])\n",
    "            target[i, action_index] = tmp_\n",
    "\n",
    "        # TD-error clipping\n",
    "        if self.use_gpu >= 0:\n",
    "            target = cuda.to_gpu(target)\n",
    "        td = Variable(target) - q  # TD error\n",
    "        td_tmp = td.data + 1000.0 * (abs(td.data) <= 1)  # Avoid zero division\n",
    "        td_clip = td * (abs(td.data) <= 1) + td/abs(td_tmp) * (abs(td.data) > 1)\n",
    "\n",
    "        zero_val = np.zeros((self.replay_size, self.num_of_actions), dtype=np.float32)\n",
    "        if self.use_gpu >= 0:\n",
    "            zero_val = cuda.to_gpu(zero_val)\n",
    "        zero_val = Variable(zero_val)\n",
    "        loss = F.mean_squared_error(td_clip, zero_val)\n",
    "        return loss, q\n",
    "\n",
    "    def stock_experience(self, time,\n",
    "                        state, action, reward, state_dash,\n",
    "                        episode_end_flag):\n",
    "        data_index = time % self.data_size\n",
    "\n",
    "        if episode_end_flag is True:\n",
    "            self.d[0][data_index] = state\n",
    "            self.d[1][data_index] = action\n",
    "            self.d[2][data_index] = reward\n",
    "        else:\n",
    "            self.d[0][data_index] = state\n",
    "            self.d[1][data_index] = action\n",
    "            self.d[2][data_index] = reward\n",
    "            self.d[3][data_index] = state_dash\n",
    "        self.d[4][data_index] = episode_end_flag\n",
    "\n",
    "    def experience_replay(self, time):\n",
    "        if self.initial_exploration < time:\n",
    "            # Pick up replay_size number of samples from the Data\n",
    "            if time < self.data_size:  # during the first sweep of the History Data\n",
    "                replay_index = np.random.randint(0, time, (self.replay_size, 1))\n",
    "            else:\n",
    "                replay_index = np.random.randint(0, self.data_size, (self.replay_size, 1))\n",
    "\n",
    "            s_replay = np.ndarray(shape=(self.replay_size, self.hist_size, self.dim), dtype=np.float32)\n",
    "            a_replay = np.ndarray(shape=(self.replay_size, 1), dtype=np.uint8)\n",
    "            r_replay = np.ndarray(shape=(self.replay_size, 1), dtype=np.float32)\n",
    "            s_dash_replay = np.ndarray(shape=(self.replay_size, self.hist_size, self.dim), dtype=np.float32)\n",
    "            episode_end_replay = np.ndarray(shape=(self.replay_size, 1), dtype=np.bool)\n",
    "            for i in xrange(self.replay_size):\n",
    "                s_replay[i] = np.asarray(self.d[0][replay_index[i]], dtype=np.float32)\n",
    "                a_replay[i] = self.d[1][replay_index[i]]\n",
    "                r_replay[i] = self.d[2][replay_index[i]]\n",
    "                s_dash_replay[i] = np.array(self.d[3][replay_index[i]], dtype=np.float32)\n",
    "                episode_end_replay[i] = self.d[4][replay_index[i]]\n",
    "\n",
    "            if self.use_gpu >= 0:\n",
    "                s_replay = cuda.to_gpu(s_replay)\n",
    "                s_dash_replay = cuda.to_gpu(s_dash_replay)\n",
    "\n",
    "            # Gradient-based update\n",
    "            self.optimizer.zero_grads()\n",
    "            loss, _ = self.forward(s_replay, a_replay, r_replay, s_dash_replay, episode_end_replay)\n",
    "            loss.backward()\n",
    "            self.optimizer.update()\n",
    "\n",
    "    def q_func(self, state):\n",
    "        h4 = F.relu(self.model.l4(state / 255.0))\n",
    "        q = self.model.q_value(h4)\n",
    "        return q\n",
    "\n",
    "    def q_func_target(self, state):\n",
    "        h4 = F.relu(self.model_target.l4(state / 255.0))\n",
    "        q = self.model_target.q_value(h4)\n",
    "        return q\n",
    "\n",
    "    def e_greedy(self, state, epsilon):\n",
    "        s = Variable(state)\n",
    "        q = self.q_func(s)\n",
    "        q = q.data\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            index_action = np.random.randint(0, self.num_of_actions)\n",
    "            print(\" Random\"),\n",
    "        else:\n",
    "            if self.use_gpu >= 0:\n",
    "                index_action = np.argmax(q.get())\n",
    "            else:\n",
    "                index_action = np.argmax(q)\n",
    "            print(\"#Greedy\"),\n",
    "        return self.index_to_action(index_action), q\n",
    "\n",
    "    def target_model_update(self):\n",
    "        self.model_target = copy.deepcopy(self.model)\n",
    "\n",
    "    def index_to_action(self, index_of_action):\n",
    "        return self.enable_controller[index_of_action]\n",
    "\n",
    "    def action_to_index(self, action):\n",
    "        return self.enable_controller.index(action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lis_DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent = CnnDqnAgent()\n",
    "agent_initialized = False\n",
    "\n",
    "cycle_counter = 0\n",
    "log_file = 'reward.log'\n",
    "reward_sum = 0\n",
    "depth_image_dim = 32 * 32\n",
    "depth_image_count = 1\n",
    "total_episode = 10000\n",
    "episode_count = 1\n",
    "gpu = 0  # gpu id (-1 to use cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing agent...\n",
      "loading... alexnet_feature_extractor.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/chainer/function_set.py:62: FutureWarning: 'collect_parameters' is deprecated. You can pass FunctionSet itself to 'optimizer.setup'\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[2017-01-18 15:48:42,967] Making new env: Lis-v2\n",
      "--- request header ---\n",
      "[2017-01-18 15:48:42,972] --- request header ---\n",
      "GET /CommunicationGym HTTP/1.1\n",
      "Upgrade: websocket\n",
      "Connection: Upgrade\n",
      "Host: localhost:4649\n",
      "Origin: http://localhost:4649\n",
      "Sec-WebSocket-Key: 0ff9M/BUDQ7DZd26E6GTkw==\n",
      "Sec-WebSocket-Version: 13\n",
      "\n",
      "\n",
      "[2017-01-18 15:48:42,974] GET /CommunicationGym HTTP/1.1\n",
      "Upgrade: websocket\n",
      "Connection: Upgrade\n",
      "Host: localhost:4649\n",
      "Origin: http://localhost:4649\n",
      "Sec-WebSocket-Key: 0ff9M/BUDQ7DZd26E6GTkw==\n",
      "Sec-WebSocket-Version: 13\n",
      "\n",
      "\n",
      "-----------------------\n",
      "[2017-01-18 15:48:42,975] -----------------------\n",
      "--- response header ---\n",
      "[2017-01-18 15:48:42,977] --- response header ---\n",
      "HTTP/1.1 101 Switching Protocols\n",
      "[2017-01-18 15:48:42,992] HTTP/1.1 101 Switching Protocols\n",
      "Server: websocket-sharp/1.0\n",
      "[2017-01-18 15:48:42,994] Server: websocket-sharp/1.0\n",
      "Upgrade: websocket\n",
      "[2017-01-18 15:48:42,995] Upgrade: websocket\n",
      "Connection: Upgrade\n",
      "[2017-01-18 15:48:42,996] Connection: Upgrade\n",
      "Sec-WebSocket-Accept: 96PDHUQTiKihmBNpw8/oREwpHQc=\n",
      "[2017-01-18 15:48:42,998] Sec-WebSocket-Accept: 96PDHUQTiKihmBNpw8/oREwpHQc=\n",
      "-----------------------\n",
      "[2017-01-18 15:48:42,999] -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Initializing Q-Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8bg\\xf0[_\\xe6W80\\n\\x9d:1\\x03Qj'\n",
      "[2017-01-18 15:48:43,329] send: '\\x81\\x8bg\\xf0[_\\xe6W80\\n\\x9d:1\\x03Qj'\n",
      "send: '\\x81\\x8bs\\xb5m\\xa3\\xf2\\x12\\x0e\\xcc\\x1e\\xd8\\x0c\\xcd\\x17\\x14]'\n",
      "[2017-01-18 15:48:43,363] send: '\\x81\\x8bs\\xb5m\\xa3\\xf2\\x12\\x0e\\xcc\\x1e\\xd8\\x0c\\xcd\\x17\\x14]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random\n",
      "Initial Exploration : 0/1000 steps Random\n",
      " Step:0  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x00b~\\xf5\\x81\\xc5\\x1d\\x9am\\x0f\\x1f\\x9bd\\xc3L'\n",
      "[2017-01-18 15:48:43,589] send: '\\x81\\x8b\\x00b~\\xf5\\x81\\xc5\\x1d\\x9am\\x0f\\x1f\\x9bd\\xc3L'\n",
      "send: '\\x81\\x8b\\x12 (\\xd7\\x93\\x87K\\xb8\\x7fMI\\xb9v\\x81\\x18'\n",
      "[2017-01-18 15:48:43,769] send: '\\x81\\x8b\\x12 (\\xd7\\x93\\x87K\\xb8\\x7fMI\\xb9v\\x81\\x18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 1/1000 steps Random\n",
      " Step:1  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 2/1000 steps Random\n",
      " Step:2  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8bk\\x1f\\x9a\\xf3\\xea\\xb8\\xf9\\x9c\\x06r\\xfb\\x9d\\x0f\\xbe\\xab'\n",
      "[2017-01-18 15:48:43,970] send: '\\x81\\x8bk\\x1f\\x9a\\xf3\\xea\\xb8\\xf9\\x9c\\x06r\\xfb\\x9d\\x0f\\xbe\\xab'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 3/1000 steps Random\n",
      " Step:3  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 4/1000 steps"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x06\\xa2\\x15\\xa5\\x87\\x05v\\xcak\\xcft\\xcbb\\x03%'\n",
      "[2017-01-18 15:48:44,170] send: '\\x81\\x8b\\x06\\xa2\\x15\\xa5\\x87\\x05v\\xcak\\xcft\\xcbb\\x03%'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random\n",
      " Step:4  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 5/1000 steps Random\n",
      " Step:5  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x83mnL\\x02\\xca\\r#\\xee\\x00\\x0f\"\\xe7\\xcc^'\n",
      "[2017-01-18 15:48:44,369] send: '\\x81\\x8b\\x83mnL\\x02\\xca\\r#\\xee\\x00\\x0f\"\\xe7\\xcc^'\n",
      "send: '\\x81\\x8bLA\\xc6\\x95\\xcd\\xe6\\xa5\\xfa!,\\xa7\\xfb(\\xe0\\xf7'\n",
      "[2017-01-18 15:48:44,549] send: '\\x81\\x8bLA\\xc6\\x95\\xcd\\xe6\\xa5\\xfa!,\\xa7\\xfb(\\xe0\\xf7'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 6/1000 steps Random\n",
      " Step:6  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\xf5\\x98%\\xeet?F\\x81\\x98\\xf5D\\x80\\x919\\x14'\n",
      "[2017-01-18 15:48:44,753] send: '\\x81\\x8b\\xf5\\x98%\\xeet?F\\x81\\x98\\xf5D\\x80\\x919\\x14'\n",
      "send: '\\x81\\x8b|-4\\xf3\\xfd\\x8aW\\x9c\\x11@U\\x9d\\x18\\x8c\\x05'\n",
      "[2017-01-18 15:48:44,941] send: '\\x81\\x8b|-4\\xf3\\xfd\\x8aW\\x9c\\x11@U\\x9d\\x18\\x8c\\x05'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 7/1000 steps Random\n",
      " Step:7  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 8/1000 steps Random\n",
      " Step:8  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b&1\\xe2\\xe9\\xa7\\x96\\x81\\x86K\\\\\\x83\\x87B\\x90\\xd0'\n",
      "[2017-01-18 15:48:45,121] send: '\\x81\\x8b&1\\xe2\\xe9\\xa7\\x96\\x81\\x86K\\\\\\x83\\x87B\\x90\\xd0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 9/1000 steps Random\n",
      " Step:9  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8bZ\\x81\\xf9\\xe1\\xdb&\\x9a\\x8e7\\xec\\x98\\x8f> \\xc9'\n",
      "[2017-01-18 15:48:45,357] send: '\\x81\\x8bZ\\x81\\xf9\\xe1\\xdb&\\x9a\\x8e7\\xec\\x98\\x8f> \\xc9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 10/1000 steps Random\n",
      " Step:10  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 11/1000 steps"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x04\\x82\\x08?\\x85%kPi\\xefiQ`#8'\n",
      "[2017-01-18 15:48:45,558] send: '\\x81\\x8b\\x04\\x82\\x08?\\x85%kPi\\xefiQ`#8'\n",
      "send: '\\x81\\x8b{c?\\x7f\\xfa\\xc4\\\\\\x10\\x16\\x0e^\\x11\\x1f\\xc2\\x0f'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random\n",
      " Step:11  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 12/1000 steps Random\n",
      " Step:12  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-18 15:48:45,757] send: '\\x81\\x8b{c?\\x7f\\xfa\\xc4\\\\\\x10\\x16\\x0e^\\x11\\x1f\\xc2\\x0f'\n",
      "send: '\\x81\\x8b\\xc2r\\xb5\\rC\\xd5\\xd6b\\xaf\\x1f\\xd4c\\xa6\\xd3\\x87'\n",
      "[2017-01-18 15:48:45,974] send: '\\x81\\x8b\\xc2r\\xb5\\rC\\xd5\\xd6b\\xaf\\x1f\\xd4c\\xa6\\xd3\\x87'\n",
      "send: '\\x81\\x8b\\xd1Y\\x17\\x96P\\xfet\\xf9\\xbc4v\\xf8\\xb5\\xf8&'\n",
      "[2017-01-18 15:48:46,157] send: '\\x81\\x8b\\xd1Y\\x17\\x96P\\xfet\\xf9\\xbc4v\\xf8\\xb5\\xf8&'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 13/1000 steps Random\n",
      " Step:13  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 14/1000 steps Random\n",
      " Step:14  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8bH\\x13\"\\xaf\\xc9\\xb4A\\xc0%~C\\xc1,\\xb2\\x13'\n",
      "[2017-01-18 15:48:46,353] send: '\\x81\\x8bH\\x13\"\\xaf\\xc9\\xb4A\\xc0%~C\\xc1,\\xb2\\x13'\n",
      "send: '\\x81\\x8b\\xd1L]\\xd2P\\xeb>\\xbd\\xbc!<\\xbc\\xb5\\xedm'\n",
      "[2017-01-18 15:48:46,541] send: '\\x81\\x8b\\xd1L]\\xd2P\\xeb>\\xbd\\xbc!<\\xbc\\xb5\\xedm'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 15/1000 steps Random\n",
      " Step:15  Action:1  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 16/1000 steps Random\n",
      " Step:16  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x06\\x19\\xf5\\xf4\\x87\\xbe\\x96\\x9bkt\\x94\\x9ab\\xb8\\xc7'\n",
      "[2017-01-18 15:48:46,757] send: '\\x81\\x8b\\x06\\x19\\xf5\\xf4\\x87\\xbe\\x96\\x9bkt\\x94\\x9ab\\xb8\\xc7'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 17/1000 steps Random\n",
      " Step:17  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x87,\\x1a)\\x06\\x8byF\\xeaA{G\\xe3\\x8d*'\n",
      "[2017-01-18 15:48:46,961] send: '\\x81\\x8b\\x87,\\x1a)\\x06\\x8byF\\xeaA{G\\xe3\\x8d*'\n",
      "send: '\\x81\\x8b\\x03\\x94\\xb9\\x11\\x823\\xda~n\\xf9\\xd8\\x7fg5\\x8b'\n",
      "[2017-01-18 15:48:47,157] send: '\\x81\\x8b\\x03\\x94\\xb9\\x11\\x823\\xda~n\\xf9\\xd8\\x7fg5\\x8b'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 18/1000 steps Random\n",
      " Step:18  Action:0  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n",
      "Initial Exploration : 19/1000 steps Random\n",
      " Step:19  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "send: '\\x81\\x8b\\x1cu\\xe3\\xca\\x9d\\xd2\\x80\\xa5q\\x18\\x82\\xa4x\\xd4\\xd1'\n",
      "[2017-01-18 15:48:47,389] send: '\\x81\\x8b\\x1cu\\xe3\\xca\\x9d\\xd2\\x80\\xa5q\\x18\\x82\\xa4x\\xd4\\xd1'\n",
      "send: '\\x88\\x82\\xf4\\x9c\\xf1\\x85\\xf7t'\n",
      "[2017-01-18 15:48:47,547] send: '\\x88\\x82\\xf4\\x9c\\xf1\\x85\\xf7t'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Exploration : 20/1000 steps Random\n",
      " Step:20  Action:2  Reward:0.0  Epsilon:1.000000  Q_max:0.000000\n"
     ]
    },
    {
     "ename": "WebSocketConnectionClosedException",
     "evalue": "Connection is already closed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d00cb25c0057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_now\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_step_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_now\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/komatsu/work/yosenabe-master/lis2/gym_client/gym/envs/unity/gym_unity_env.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Unity Process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_episode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/komatsu/work/yosenabe-master/lis2/gym_client/gym/envs/unity/gym_unity_env.pyc\u001b[0m in \u001b[0;36mreceive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mstatedata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstatedata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_core.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_core.pyc\u001b[0m in \u001b[0;36mrecv_data\u001b[0;34m(self, control_frame)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_core.pyc\u001b[0m in \u001b[0;36mrecv_data_frame\u001b[0;34m(self, control_frame)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;31m# handle error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_core.pyc\u001b[0m in \u001b[0;36mrecv_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mABNF\u001b[0m \u001b[0mframe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \"\"\"\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTATUS_NORMAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_abnf.pyc\u001b[0m in \u001b[0;36mrecv_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_received_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_abnf.pyc\u001b[0m in \u001b[0;36mrecv_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_abnf.pyc\u001b[0m in \u001b[0;36mrecv_strict\u001b[0;34m(self, bufsize)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;31m# buffers allocated and then shrunk, which results in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# fragmentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mbytes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mshortage\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_core.pyc\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, bufsize)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWebSocketConnectionClosedException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/websocket/_socket.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(sock, bufsize)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbytes_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise WebSocketConnectionClosedException(\n\u001b[0;32m---> 93\u001b[0;31m             \"Connection is already closed.\")\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebSocketConnectionClosedException\u001b[0m: Connection is already closed."
     ]
    }
   ],
   "source": [
    "while episode_count <= total_episode:\n",
    "    if not agent_initialized:\n",
    "        agent_initialized = True\n",
    "        print (\"initializing agent...\")\n",
    "        agent.agent_init(\n",
    "            use_gpu=gpu,\n",
    "            depth_image_dim=depth_image_dim * depth_image_count)\n",
    "\n",
    "        env = gym.make('Lis-v2')\n",
    "\n",
    "        observation = env.reset()  \n",
    "        action = agent.agent_start(observation) \n",
    "        observation, reward, end_episode, _ = env.step(action)  \n",
    "\n",
    "        with open(log_file, 'w') as the_file:\n",
    "            the_file.write('cycle, episode_reward_sum \\n')\n",
    "    else:\n",
    "        cycle_counter += 1  \n",
    "        reward_sum += reward\n",
    "\n",
    "        if end_episode:\n",
    "            agent.agent_end(reward)\n",
    "\n",
    "            \n",
    "            action = agent.agent_start(observation)  # TODO\n",
    "            observation, reward, end_episode, _ = env.step(action)\n",
    "\n",
    "            with open(log_file, 'a') as the_file:\n",
    "                the_file.write(str(cycle_counter) +\n",
    "                               ',' + str(reward_sum) + '\\n')\n",
    "            reward_sum = 0\n",
    "            episode_count += 1\n",
    "\n",
    "        else:\n",
    "            action, eps, q_now, obs_array = agent.agent_step(reward, observation)  \n",
    "            agent.agent_step_update(reward, action, eps, q_now, obs_array)\n",
    "            observation, reward, end_episode, _ = env.step(action)  \n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
