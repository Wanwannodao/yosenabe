{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine turning\n",
    "以下のサイトを参考に\n",
    "http://qiita.com/tabe2314/items/6c0c1b769e12ab1e2614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer import Variable\n",
    "import copy # test iterator copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def copy_model(src, dst):\n",
    "    assert isinstance(src, chainer.link.Chain)\n",
    "    assert isinstance(dst, chainer.link.Chain)\n",
    "    for child in src.children():\n",
    "        if child.name not in dst.__dict__: continue\n",
    "        dst_child = dst[child.name]\n",
    "        if type(child) != type(dst_child): continue\n",
    "        if isinstance(child, chainer.link.Chain):\n",
    "            copy_model(child, dst_child)\n",
    "        if isinstance(child, chainer.link.Link):\n",
    "            match = True\n",
    "            for a, b in zip(child.namedparams(), dst_child.namedparams()):\n",
    "                if a[0] != b[0]:\n",
    "                    match = False\n",
    "                    break\n",
    "                if a[1].data.shape != b[1].data.shape:\n",
    "                    match = False\n",
    "                    break\n",
    "            if not match:\n",
    "                print('Ignore %s because of parameter mismatch' % child.name)\n",
    "                continue\n",
    "            for a, b in zip(child.namedparams(), dst_child.namedparams()):\n",
    "                b[1].data = a[1].data\n",
    "            print('Copy %s' % child.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "# dataset = 'mnist'\n",
    "\n",
    "batchsize = 128\n",
    "epochsize = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CIFAR10 dataset.\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'cifar10':\n",
    "    print('Using CIFAR10 dataset.')\n",
    "    class_labels = 10\n",
    "    train, test = chainer.datasets.get_cifar10()\n",
    "elif dataset == 'cifar100':\n",
    "    print('Using CIFAR100 dataset.')\n",
    "    class_labels = 100\n",
    "    train, test = chainer.datasets.get_cifar100()\n",
    "elif dataset == 'mnist':\n",
    "    print('Using mnist dataset.')\n",
    "    class_labels = 10\n",
    "    train, test = chainer.datasets.get_mnist()\n",
    "    train = [(it[0].reshape(1, 28, 28),it[1]) for it in train]\n",
    "    test = [(it[0].reshape(1, 28, 28),it[1]) for it in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cifar dataset\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "testsize = len(test)\n",
    "testsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer.links.caffe import CaffeFunction\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "CAFFE_MODEL_NAME = 'VGG_ILSVRC_16_layers.caffemodel'\n",
    "OUTPUT_NAME = 'vgg16.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = CaffeFunction('/home/komatsu/Downloads/'+CAFFE_MODEL_NAME)\n",
    "pickle.dump(vgg, open('/home/komatsu/work/yosenabe/practices/chainer_pkl/'+OUTPUT_NAME, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "vgg= pickle.load(open('/home/komatsu/work/yosenabe/practices/chainer_pkl/'+OUTPUT_NAME, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'/conv1_1/W', <variable W>)\n",
      "(u'/conv1_1/b', <variable b>)\n",
      "(u'/conv1_2/W', <variable W>)\n",
      "(u'/conv1_2/b', <variable b>)\n",
      "(u'/conv2_1/W', <variable W>)\n",
      "(u'/conv2_1/b', <variable b>)\n",
      "(u'/conv2_2/W', <variable W>)\n",
      "(u'/conv2_2/b', <variable b>)\n",
      "(u'/conv3_1/W', <variable W>)\n",
      "(u'/conv3_1/b', <variable b>)\n",
      "(u'/conv3_2/W', <variable W>)\n",
      "(u'/conv3_2/b', <variable b>)\n",
      "(u'/conv3_3/W', <variable W>)\n",
      "(u'/conv3_3/b', <variable b>)\n",
      "(u'/conv4_1/W', <variable W>)\n",
      "(u'/conv4_1/b', <variable b>)\n",
      "(u'/conv4_2/W', <variable W>)\n",
      "(u'/conv4_2/b', <variable b>)\n",
      "(u'/conv4_3/W', <variable W>)\n",
      "(u'/conv4_3/b', <variable b>)\n",
      "(u'/conv5_1/W', <variable W>)\n",
      "(u'/conv5_1/b', <variable b>)\n",
      "(u'/conv5_2/W', <variable W>)\n",
      "(u'/conv5_2/b', <variable b>)\n",
      "(u'/conv5_3/W', <variable W>)\n",
      "(u'/conv5_3/b', <variable b>)\n",
      "(u'/fc6/W', <variable W>)\n",
      "(u'/fc6/b', <variable b>)\n",
      "(u'/fc7/W', <variable W>)\n",
      "(u'/fc7/b', <variable b>)\n",
      "(u'/fc8/W', <variable W>)\n",
      "(u'/fc8/b', <variable b>)\n"
     ]
    }
   ],
   "source": [
    "for it in vgg.namedparams():\n",
    "    print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG(chainer.Chain):\n",
    "    def __init__(self, class_labels):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "        super(VGG, self).__init__(\n",
    "             # the size of the inputs to each layer will be inferred\n",
    "            conv1_1=L.Convolution2D(3, 64, 3, stride=1, pad=1),\n",
    "            conv1_2=L.Convolution2D(64, 64, 3, stride=1, pad=1),\n",
    "            conv2_1=L.Convolution2D(64, 128, 3, stride=1, pad=1),\n",
    "            conv2_2=L.Convolution2D(128, 128, 3, stride=1, pad=1),\n",
    "            conv3_1=L.Convolution2D(128, 256, 3, stride=1, pad=1),\n",
    "            conv3_2=L.Convolution2D(256, 256, 3, stride=1, pad=1),\n",
    "            conv3_3=L.Convolution2D(256, 256, 3, stride=1, pad=1),\n",
    "            conv4_1=L.Convolution2D(256, 512, 3, stride=1, pad=1),\n",
    "            conv4_2=L.Convolution2D(512, 512, 3, stride=1, pad=1),\n",
    "            conv4_3=L.Convolution2D(512, 512, 3, stride=1, pad=1),\n",
    "            new_fc5 = L.Linear(512*2*2, 1000, initialW=initializer),\n",
    "            new_fc6 = L.Linear(1000, class_labels, initialW=initializer),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1_1(x))\n",
    "        h = F.relu(self.conv1_2(h))\n",
    "        h = F.max_pooling_2d(h, 2, stride=2)\n",
    "        \n",
    "        h = F.relu(self.conv2_1(h))\n",
    "        h = F.relu(self.conv2_2(h))\n",
    "        h = F.max_pooling_2d(h, 2, stride=2)\n",
    "\n",
    "        h = F.relu(self.conv3_1(h))\n",
    "        h = F.relu(self.conv3_2(h))\n",
    "        h = F.relu(self.conv3_3(h))\n",
    "        h = F.max_pooling_2d(h, 2, stride=2)\n",
    "\n",
    "        h = F.relu(self.conv4_1(h))\n",
    "        h = F.relu(self.conv4_2(h))\n",
    "        h = F.relu(self.conv4_3(h))\n",
    "        h = F.max_pooling_2d(h, 2, stride=2)\n",
    "        \n",
    "        h = F.relu(self.new_fc5(h))\n",
    "        y = self.new_fc6(h)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_vgg = VGG(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from Caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.16854778, -0.12473571, -0.13066512],\n",
       "        [ 0.03298501,  0.09515205,  0.32222724],\n",
       "        [ 0.02890779,  0.08020072, -0.36099228]],\n",
       "\n",
       "       [[ 0.21751988,  0.30467194,  0.26698956],\n",
       "        [ 0.17851426, -0.1768859 , -0.00296475],\n",
       "        [ 0.02764448,  0.33886912, -0.15486431]],\n",
       "\n",
       "       [[ 0.0387103 , -0.67247236,  0.09884518],\n",
       "        [ 0.03921968, -0.13343205, -0.11175998],\n",
       "        [-0.13195056,  0.16540597, -0.11617035]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vgg['conv1_1'].W.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy conv1_1\n",
      "Copy conv1_2\n",
      "Copy conv2_1\n",
      "Copy conv2_2\n",
      "Copy conv3_1\n",
      "Copy conv3_2\n",
      "Copy conv3_3\n",
      "Copy conv4_1\n",
      "Copy conv4_2\n",
      "Copy conv4_3\n"
     ]
    }
   ],
   "source": [
    "copy_model(vgg, new_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.42947057,  0.373467  , -0.06136011],\n",
       "        [ 0.27476987,  0.03868078, -0.36722335],\n",
       "        [-0.05746817, -0.26224968, -0.35009676]],\n",
       "\n",
       "       [[ 0.55037946,  0.44007453, -0.08138704],\n",
       "        [ 0.34573907,  0.04063221, -0.45350131],\n",
       "        [-0.05863491, -0.33066967, -0.4850302 ]],\n",
       "\n",
       "       [[ 0.4800154 ,  0.4085474 , -0.06514555],\n",
       "        [ 0.31047726,  0.05020237, -0.40338343],\n",
       "        [-0.05087169, -0.28522751, -0.41851634]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg['conv1_1'].W.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.42947057,  0.373467  , -0.06136011],\n",
       "        [ 0.27476987,  0.03868078, -0.36722335],\n",
       "        [-0.05746817, -0.26224968, -0.35009676]],\n",
       "\n",
       "       [[ 0.55037946,  0.44007453, -0.08138704],\n",
       "        [ 0.34573907,  0.04063221, -0.45350131],\n",
       "        [-0.05863491, -0.33066967, -0.4850302 ]],\n",
       "\n",
       "       [[ 0.4800154 ,  0.4085474 , -0.06514555],\n",
       "        [ 0.31047726,  0.05020237, -0.40338343],\n",
       "        [-0.05087169, -0.28522751, -0.41851634]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vgg['conv1_1'].W.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__(predictor=predictor)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        self.clear()\n",
    "        y = self.predictor(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        self.accuracy = F.accuracy(y, t)\n",
    "        chainer.report({'loss': loss, 'accuracy': self.accuracy}, self)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup a model\n",
    "gpu_id = 0 #  use gpu\n",
    "model = Classifier(new_vgg)\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    chainer.cuda.get_device(gpu_id).use()  # Make a specified GPU current\n",
    "    model.to_gpu()  # Copy the model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup an optimizer\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "# optimizer.add_hook(chainer.optimizer.WeightDecay(5e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "8.82952594757\n"
     ]
    }
   ],
   "source": [
    "# model error check\n",
    "batch = train_iter.next()\n",
    "xp = model.xp\n",
    "x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "t = xp.asarray([it[1] for it in batch], dtype=np.int32)\n",
    "print(x[0].shape)\n",
    "# predict without Classifier\n",
    "y = model.predictor(x)\n",
    "loss = F.softmax_cross_entropy(y, t)\n",
    "model.cleargrads()\n",
    "loss.backward()\n",
    "optimizer.update()\n",
    "#print(y.data)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, Mean loss: 1.19482350349, Mean accuracy: 0.568000018597\n",
      "epoch : 1, Mean loss: 0.910808622837, Mean accuracy: 0.677100002766\n",
      "epoch : 2, Mean loss: 0.712756276131, Mean accuracy: 0.760100007057\n",
      "epoch : 3, Mean loss: 0.64687359333, Mean accuracy: 0.787899971008\n",
      "epoch : 4, Mean loss: 0.637249410152, Mean accuracy: 0.793699979782\n",
      "epoch : 5, Mean loss: 0.644981026649, Mean accuracy: 0.793099999428\n",
      "epoch : 6, Mean loss: 0.635182619095, Mean accuracy: 0.800100028515\n",
      "epoch : 7, Mean loss: 0.675313711166, Mean accuracy: 0.810100018978\n",
      "epoch : 8, Mean loss: 0.627174675465, Mean accuracy: 0.807299971581\n",
      "epoch : 9, Mean loss: 0.679122328758, Mean accuracy: 0.810299992561\n",
      "epoch : 10, Mean loss: 0.714975953102, Mean accuracy: 0.800499975681\n",
      "epoch : 11, Mean loss: 0.785280585289, Mean accuracy: 0.812699973583\n",
      "epoch : 12, Mean loss: 0.814564526081, Mean accuracy: 0.799499988556\n",
      "epoch : 13, Mean loss: 0.742326855659, Mean accuracy: 0.806999981403\n",
      "epoch : 14, Mean loss: 0.786305963993, Mean accuracy: 0.807500004768\n",
      "epoch : 15, Mean loss: 0.854012310505, Mean accuracy: 0.822600007057\n",
      "epoch : 16, Mean loss: 0.811595678329, Mean accuracy: 0.813799977303\n",
      "epoch : 17, Mean loss: 0.881706953049, Mean accuracy: 0.800300002098\n",
      "epoch : 18, Mean loss: 0.860821008682, Mean accuracy: 0.806599974632\n",
      "epoch : 19, Mean loss: 0.897294938564, Mean accuracy: 0.803699970245\n",
      "epoch : 20, Mean loss: 0.871382892132, Mean accuracy: 0.804400026798\n",
      "epoch : 21, Mean loss: 0.96928268671, Mean accuracy: 0.799799978733\n",
      "epoch : 22, Mean loss: 1.02862608433, Mean accuracy: 0.813799977303\n",
      "epoch : 23, Mean loss: 0.988436222076, Mean accuracy: 0.819100022316\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# run\n",
    "xp = model.xp\n",
    "\n",
    "pbar = tqdm(xrange(epochsize), desc='epoch loop')\n",
    "for epoch in pbar:\n",
    "    for batch in train_iter:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        # terminate\n",
    "        if train_iter.is_new_epoch is True:\n",
    "            break\n",
    "\n",
    "    # evaluate model   \n",
    "    sum_loss = 0\n",
    "    sum_acc = 0\n",
    "    test_iter_copy = copy.copy(test_iter)\n",
    "    for test_batch in test_iter_copy:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in test_batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in test_batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        sum_loss += loss.data * len(test_batch)\n",
    "        sum_acc += model.accuracy.data * len(test_batch)\n",
    "    mean_loss = sum_loss / testsize\n",
    "    mean_acc = sum_acc / testsize\n",
    "#     print(''.format(epoch=epoch))\n",
    "    print('epoch : {epoch}, Mean loss: {loss}, Mean accuracy: {acc}'.format(epoch=epoch, loss=mean_loss, acc=mean_acc))\n",
    "    # pbar.set_description('epoch : {epoch}'.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下うまく行かなかった例\n",
    "Caffemodelのまま，層を変えれば良いと思ったがよくわからないエラーがでて断念した  \n",
    "また，Caffemodelだとエラー時に何が起こっているかわからないため，\n",
    "モデルは自分で書いたほうが良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Last layter for cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__(predictor=predictor)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        self.clear()\n",
    "        y = self.predictor(inputs={'data': x}, outputs=['prob'])\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        self.accuracy = F.accuracy(y, t)\n",
    "        chainer.report({'loss': loss, 'accuracy': self.accuracy}, self)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg['fc7'].W.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4096)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg['fc8'].W.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_fc6 = L.Linear(512, 1000)\n",
    "new_fc7 = L.Linear(1000, 1000)\n",
    "new_fc8 = L.Linear(1000, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00398499,  0.04089545,  0.01618574, ...,  0.02687539,\n",
       "        -0.00602881,  0.00047246],\n",
       "       [-0.0082648 ,  0.00478303, -0.03781039, ..., -0.01898056,\n",
       "        -0.01351354, -0.00123579],\n",
       "       [-0.04749636, -0.06221081,  0.01145141, ...,  0.02494635,\n",
       "        -0.02649529, -0.0293122 ],\n",
       "       ..., \n",
       "       [-0.01758477,  0.01283393, -0.06990477, ..., -0.00308131,\n",
       "         0.04999574,  0.04004084],\n",
       "       [ 0.00892289,  0.01961285, -0.02511998, ...,  0.07210597,\n",
       "         0.01343249,  0.02732559],\n",
       "       [ 0.02318517,  0.06497291, -0.00266213, ...,  0.06236425,\n",
       "        -0.05052614, -0.00730087]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fc7.W.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fc8.W.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg['fc6'].W = new_fc6.W\n",
    "vgg['fc6'].b = new_fc6.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg['fc7'].W = new_fc7.W\n",
    "vgg['fc7'].b = new_fc7.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg['fc8'].W = new_fc8.W\n",
    "vgg['fc8'].b = new_fc8.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_children': [u'conv1_1',\n",
       "  u'conv1_2',\n",
       "  u'conv2_1',\n",
       "  u'conv2_2',\n",
       "  u'conv3_1',\n",
       "  u'conv3_2',\n",
       "  u'conv3_3',\n",
       "  u'conv3_4',\n",
       "  u'conv4_1',\n",
       "  u'conv4_2',\n",
       "  u'conv4_3',\n",
       "  u'conv4_4',\n",
       "  u'conv5_1',\n",
       "  u'conv5_2',\n",
       "  u'conv5_3',\n",
       "  u'conv5_4',\n",
       "  u'fc6',\n",
       "  u'fc7',\n",
       "  u'fc8'],\n",
       " '_cpu': False,\n",
       " '_device_id': 0,\n",
       " '_params': [],\n",
       " '_persistent': [],\n",
       " '_uninitialized_params': {},\n",
       " u'conv1_1': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acb2a4ad0>,\n",
       " u'conv1_2': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acb2a4bd0>,\n",
       " u'conv2_1': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97b10>,\n",
       " u'conv2_2': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97a10>,\n",
       " u'conv3_1': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97910>,\n",
       " u'conv3_2': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97810>,\n",
       " u'conv3_3': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97710>,\n",
       " u'conv3_4': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97610>,\n",
       " u'conv4_1': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97310>,\n",
       " u'conv4_2': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97410>,\n",
       " u'conv4_3': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97510>,\n",
       " u'conv4_4': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97c10>,\n",
       " u'conv5_1': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acb2a4dd0>,\n",
       " u'conv5_2': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acaf97110>,\n",
       " u'conv5_3': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acb2a4fd0>,\n",
       " u'conv5_4': <chainer.links.connection.convolution_2d.Convolution2D at 0x7f2acb2a4cd0>,\n",
       " u'fc6': <chainer.links.connection.linear.Linear at 0x7f2acb2a4ed0>,\n",
       " u'fc7': <chainer.links.connection.linear.Linear at 0x7f2acaf97210>,\n",
       " u'fc8': <chainer.links.connection.linear.Linear at 0x7f2acb2a4990>,\n",
       " 'forwards': {u'conv1_1': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4350>,\n",
       "  u'conv1_2': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4410>,\n",
       "  u'conv2_1': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4910>,\n",
       "  u'conv2_2': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4890>,\n",
       "  u'conv3_1': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4750>,\n",
       "  u'conv3_2': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4710>,\n",
       "  u'conv3_3': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a46d0>,\n",
       "  u'conv3_4': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4690>,\n",
       "  u'conv4_1': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4590>,\n",
       "  u'conv4_2': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a45d0>,\n",
       "  u'conv4_3': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4610>,\n",
       "  u'conv4_4': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4550>,\n",
       "  u'conv5_1': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4490>,\n",
       "  u'conv5_2': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4510>,\n",
       "  u'conv5_3': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a44d0>,\n",
       "  u'conv5_4': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acb2a4450>,\n",
       "  u'drop6': <chainer.links.caffe.caffe_function._DropoutFunction at 0x7f2acb2a43d0>,\n",
       "  u'drop7': <chainer.links.caffe.caffe_function._DropoutFunction at 0x7f2acb2a4650>,\n",
       "  u'fc6': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acafb4f50>,\n",
       "  u'fc7': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2acafb4d90>,\n",
       "  u'fc8': <chainer.links.caffe.caffe_function._CallChildLink at 0x7f2afc4e7990>,\n",
       "  u'pool1': <chainer.links.caffe.caffe_function._SingleArgumentFunction at 0x7f2acb2a4850>,\n",
       "  u'pool2': <chainer.links.caffe.caffe_function._SingleArgumentFunction at 0x7f2acb2a4810>,\n",
       "  u'pool3': <chainer.links.caffe.caffe_function._SingleArgumentFunction at 0x7f2acb2a47d0>,\n",
       "  u'pool4': <chainer.links.caffe.caffe_function._SingleArgumentFunction at 0x7f2acb2a4950>,\n",
       "  u'pool5': <chainer.links.caffe.caffe_function._SingleArgumentFunction at 0x7f2acb2a48d0>,\n",
       "  u'prob': <function chainer.functions.activation.softmax.softmax>,\n",
       "  u'relu1_1': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu1_2': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu2_1': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu2_2': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu3_1': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu3_2': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu3_3': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu3_4': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu4_1': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu4_2': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu4_3': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu4_4': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu5_1': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu5_2': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu5_3': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu5_4': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu6': <function chainer.functions.activation.relu.relu>,\n",
       "  u'relu7': <function chainer.functions.activation.relu.relu>},\n",
       " 'layers': [(u'conv1_1', [u'data'], [u'conv1_1']),\n",
       "  (u'relu1_1', [u'conv1_1'], [u'conv1_1']),\n",
       "  (u'conv1_2', [u'conv1_1'], [u'conv1_2']),\n",
       "  (u'relu1_2', [u'conv1_2'], [u'conv1_2']),\n",
       "  (u'pool1', [u'conv1_2'], [u'pool1']),\n",
       "  (u'conv2_1', [u'pool1'], [u'conv2_1']),\n",
       "  (u'relu2_1', [u'conv2_1'], [u'conv2_1']),\n",
       "  (u'conv2_2', [u'conv2_1'], [u'conv2_2']),\n",
       "  (u'relu2_2', [u'conv2_2'], [u'conv2_2']),\n",
       "  (u'pool2', [u'conv2_2'], [u'pool2']),\n",
       "  (u'conv3_1', [u'pool2'], [u'conv3_1']),\n",
       "  (u'relu3_1', [u'conv3_1'], [u'conv3_1']),\n",
       "  (u'conv3_2', [u'conv3_1'], [u'conv3_2']),\n",
       "  (u'relu3_2', [u'conv3_2'], [u'conv3_2']),\n",
       "  (u'conv3_3', [u'conv3_2'], [u'conv3_3']),\n",
       "  (u'relu3_3', [u'conv3_3'], [u'conv3_3']),\n",
       "  (u'conv3_4', [u'conv3_3'], [u'conv3_4']),\n",
       "  (u'relu3_4', [u'conv3_4'], [u'conv3_4']),\n",
       "  (u'pool3', [u'conv3_4'], [u'pool3']),\n",
       "  (u'conv4_1', [u'pool3'], [u'conv4_1']),\n",
       "  (u'relu4_1', [u'conv4_1'], [u'conv4_1']),\n",
       "  (u'conv4_2', [u'conv4_1'], [u'conv4_2']),\n",
       "  (u'relu4_2', [u'conv4_2'], [u'conv4_2']),\n",
       "  (u'conv4_3', [u'conv4_2'], [u'conv4_3']),\n",
       "  (u'relu4_3', [u'conv4_3'], [u'conv4_3']),\n",
       "  (u'conv4_4', [u'conv4_3'], [u'conv4_4']),\n",
       "  (u'relu4_4', [u'conv4_4'], [u'conv4_4']),\n",
       "  (u'pool4', [u'conv4_4'], [u'pool4']),\n",
       "  (u'conv5_1', [u'pool4'], [u'conv5_1']),\n",
       "  (u'relu5_1', [u'conv5_1'], [u'conv5_1']),\n",
       "  (u'conv5_2', [u'conv5_1'], [u'conv5_2']),\n",
       "  (u'relu5_2', [u'conv5_2'], [u'conv5_2']),\n",
       "  (u'conv5_3', [u'conv5_2'], [u'conv5_3']),\n",
       "  (u'relu5_3', [u'conv5_3'], [u'conv5_3']),\n",
       "  (u'conv5_4', [u'conv5_3'], [u'conv5_4']),\n",
       "  (u'relu5_4', [u'conv5_4'], [u'conv5_4']),\n",
       "  (u'pool5', [u'conv5_4'], [u'pool5']),\n",
       "  (u'fc6', [u'pool5'], [u'fc6']),\n",
       "  (u'relu6', [u'fc6'], [u'fc6']),\n",
       "  (u'drop6', [u'fc6'], [u'fc6']),\n",
       "  (u'fc7', [u'fc6'], [u'fc7']),\n",
       "  (u'relu7', [u'fc7'], [u'fc7']),\n",
       "  (u'drop7', [u'fc7'], [u'fc7']),\n",
       "  (u'fc8', [u'fc7'], [u'fc8']),\n",
       "  (u'prob', [u'fc8'], [u'prob'])],\n",
       " 'name': 'predictor',\n",
       " 'split_map': {},\n",
       " 'train': True}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'conv1_1', [u'data'], [u'conv1_1']),\n",
       " (u'relu1_1', [u'conv1_1'], [u'conv1_1']),\n",
       " (u'conv1_2', [u'conv1_1'], [u'conv1_2']),\n",
       " (u'relu1_2', [u'conv1_2'], [u'conv1_2']),\n",
       " (u'pool1', [u'conv1_2'], [u'pool1']),\n",
       " (u'conv2_1', [u'pool1'], [u'conv2_1']),\n",
       " (u'relu2_1', [u'conv2_1'], [u'conv2_1']),\n",
       " (u'conv2_2', [u'conv2_1'], [u'conv2_2']),\n",
       " (u'relu2_2', [u'conv2_2'], [u'conv2_2']),\n",
       " (u'pool2', [u'conv2_2'], [u'pool2']),\n",
       " (u'conv3_1', [u'pool2'], [u'conv3_1']),\n",
       " (u'relu3_1', [u'conv3_1'], [u'conv3_1']),\n",
       " (u'conv3_2', [u'conv3_1'], [u'conv3_2']),\n",
       " (u'relu3_2', [u'conv3_2'], [u'conv3_2']),\n",
       " (u'conv3_3', [u'conv3_2'], [u'conv3_3']),\n",
       " (u'relu3_3', [u'conv3_3'], [u'conv3_3']),\n",
       " (u'conv3_4', [u'conv3_3'], [u'conv3_4']),\n",
       " (u'relu3_4', [u'conv3_4'], [u'conv3_4']),\n",
       " (u'pool3', [u'conv3_4'], [u'pool3']),\n",
       " (u'conv4_1', [u'pool3'], [u'conv4_1']),\n",
       " (u'relu4_1', [u'conv4_1'], [u'conv4_1']),\n",
       " (u'conv4_2', [u'conv4_1'], [u'conv4_2']),\n",
       " (u'relu4_2', [u'conv4_2'], [u'conv4_2']),\n",
       " (u'conv4_3', [u'conv4_2'], [u'conv4_3']),\n",
       " (u'relu4_3', [u'conv4_3'], [u'conv4_3']),\n",
       " (u'conv4_4', [u'conv4_3'], [u'conv4_4']),\n",
       " (u'relu4_4', [u'conv4_4'], [u'conv4_4']),\n",
       " (u'pool4', [u'conv4_4'], [u'pool4']),\n",
       " (u'conv5_1', [u'pool4'], [u'conv5_1']),\n",
       " (u'relu5_1', [u'conv5_1'], [u'conv5_1']),\n",
       " (u'conv5_2', [u'conv5_1'], [u'conv5_2']),\n",
       " (u'relu5_2', [u'conv5_2'], [u'conv5_2']),\n",
       " (u'conv5_3', [u'conv5_2'], [u'conv5_3']),\n",
       " (u'relu5_3', [u'conv5_3'], [u'conv5_3']),\n",
       " (u'conv5_4', [u'conv5_3'], [u'conv5_4']),\n",
       " (u'relu5_4', [u'conv5_4'], [u'conv5_4']),\n",
       " (u'pool5', [u'conv5_4'], [u'pool5']),\n",
       " (u'fc6', [u'pool5'], [u'fc6']),\n",
       " (u'relu6', [u'fc6'], [u'fc6']),\n",
       " (u'drop6', [u'fc6'], [u'fc6']),\n",
       " (u'fc7', [u'fc6'], [u'fc7']),\n",
       " (u'relu7', [u'fc7'], [u'fc7']),\n",
       " (u'drop7', [u'fc7'], [u'fc7']),\n",
       " (u'fc8', [u'fc7'], [u'fc8']),\n",
       " (u'prob', [u'fc8'], [u'prob'])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = train_iter.next()\n",
    "x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "t = xp.asarray([it[1] for it in batch], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.links.caffe.caffe_function.CaffeFunction at 0x7f2acaff7d50>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chainer.cuda.get_device(gpu_id).use()  # Make a specified GPU current\n",
    "vgg.to_cpu()  # Copy the model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "given link is already registered to another chain by name predictor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-b9a78619c041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgpu_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#  use gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgpu_id\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make a specified GPU current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4ab14a31fb20>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, predictor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/komatsu/anaconda2/lib/python2.7/site-packages/chainer/link.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **links)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/komatsu/anaconda2/lib/python2.7/site-packages/chainer/link.pyc\u001b[0m in \u001b[0;36madd_link\u001b[0;34m(self, name, link)\u001b[0m\n\u001b[1;32m    591\u001b[0m             raise ValueError(\n\u001b[1;32m    592\u001b[0m                 \u001b[0;34m'given link is already registered to another chain by name %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 % link.name)\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: given link is already registered to another chain by name predictor"
     ]
    }
   ],
   "source": [
    "gpu_id = 0 #  use gpu\n",
    "model = Classifier(vgg)\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    chainer.cuda.get_device(gpu_id).use()  # Make a specified GPU current\n",
    "    model.to_gpu()  # Copy the model to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d239774ebad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# compute grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4ab14a31fb20>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# run\n",
    "xp = model.xp\n",
    "\n",
    "pbar = tqdm(xrange(epochsize))\n",
    "for epoch in pbar:\n",
    "    for batch in train_iter:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        # terminate\n",
    "        if train_iter.is_new_epoch is True:\n",
    "            break\n",
    "\n",
    "    # evaluate model   \n",
    "    sum_loss = 0\n",
    "    sum_acc = 0\n",
    "    test_iter_copy = copy.copy(test_iter)\n",
    "    for test_batch in test_iter_copy:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in test_batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in test_batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        sum_loss += loss.data * len(test_batch)\n",
    "        sum_acc += model.accuracy.data * len(test_batch)\n",
    "    mean_loss = sum_loss / testsize\n",
    "    mean_acc = sum_acc / testsize\n",
    "#     print(''.format(epoch=epoch))\n",
    "    print('epoch : {epoch}, Mean loss: {loss}, Mean accuracy: {acc}'.format(epoch=epoch, loss=mean_loss, acc=mean_acc))\n",
    "    # pbar.set_description('epoch : {epoch}'.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-407b3933cb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "model.predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'instancemethod' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-647f92941473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc8'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'instancemethod' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-06a0f3a3f855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "0d74f85840e34e0494ebe017ad265485": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "8aacce56995d4c95adbb32908380d970": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "9406cc6eb5fb418ea8e582dc9ebe8f65": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "9a5c7b80f30b464682d9fdffa8137a26": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
