{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer cifar10 tutorial\n",
    "自分の理解が深まるように少し改変  \n",
    "https://github.com/pfnet/chainer/blob/master/examples/cifar/train_cifar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer import Variable\n",
    "import copy # test iterator copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = 'cifar10'\n",
    "dataset = 'mnist'\n",
    "\n",
    "batchsize = 128\n",
    "epochsize = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mnist dataset.\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'cifar10':\n",
    "    print('Using CIFAR10 dataset.')\n",
    "    class_labels = 10\n",
    "    train, test = chainer.datasets.get_cifar10()\n",
    "elif dataset == 'cifar100':\n",
    "    print('Using CIFAR100 dataset.')\n",
    "    class_labels = 100\n",
    "    train, test = chainer.datasets.get_cifar100()\n",
    "elif dataset == 'mnist':\n",
    "    print('Using mnist dataset.')\n",
    "    class_labels = 10\n",
    "    train, test = chainer.datasets.get_mnist()\n",
    "    train = [(it[0].reshape(1, 28, 28),it[1]) for it in train]\n",
    "    test = [(it[0].reshape(1, 28, 28),it[1]) for it in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train = [(it[0].flatten(),it[1]) for it in train]\n",
    "# test = [(it[0].flatten(),it[1]) for it in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cifar dataset\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "testsize = len(test)\n",
    "testsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VGG(chainer.Chain):\n",
    "    def __init__(self, class_labels):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "        super(VGG, self).__init__(\n",
    "             # the size of the inputs to each layer will be inferred\n",
    "            conv1=L.Convolution2D(None, 32, 3, stride=1, pad=0),\n",
    "            conv2=L.Convolution2D(32, 64, 3, stride=1, pad=0),\n",
    "            fc3=L.Linear(64*6*6, 1000, initialW=initializer),\n",
    "            fc4=L.Linear(1000, class_labels, initialW=initializer),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.max_pooling_2d(F.relu(self.conv1(x)), 2, stride=2)\n",
    "        h = F.max_pooling_2d(F.relu(self.conv2(h)), 2, stride=2)        \n",
    "        h = self.fc3(h)\n",
    "        y = self.fc4(h)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Classifier(chainer.Chain):\n",
    "    def __init__(self, predictor):\n",
    "        super(Classifier, self).__init__(predictor=predictor)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        self.clear()\n",
    "        y = self.predictor(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        self.accuracy = F.accuracy(y, t)\n",
    "        chainer.report({'loss': loss, 'accuracy': self.accuracy}, self)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "gpu_id = 0 #  use gpu\n",
    "model = Classifier(VGG(class_labels))\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    chainer.cuda.get_device(gpu_id).use()  # Make a specified GPU current\n",
    "    model.to_gpu()  # Copy the model to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = chainer.optimizers.MomentumSGD(0.1)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(5e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cupy' from '/home/komatsu/anaconda2/lib/python2.7/site-packages/cupy/__init__.pyc'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp = model.xp\n",
    "xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "t = xp.asarray([it[1] for it in batch], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45369696617\n"
     ]
    }
   ],
   "source": [
    "# predict without Classifier\n",
    "y = model.predictor(x)\n",
    "loss = F.softmax_cross_entropy(y, t)\n",
    "#print(y.data)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53663039,  0.02479448, -0.24313273, ...,  0.60040087,\n",
       "         0.10376104,  0.91054815],\n",
       "       [ 0.73547   , -0.15444329, -0.33329362, ...,  0.68617147,\n",
       "        -0.3283636 ,  0.18050759],\n",
       "       [ 0.69740087,  0.36584252, -0.567967  , ...,  0.57524574,\n",
       "        -0.48962125,  0.24601667],\n",
       "       ..., \n",
       "       [ 0.18055549,  0.34818384, -0.45530042, ...,  0.50181001,\n",
       "        -0.35842976, -0.60386521],\n",
       "       [ 0.15093195, -0.54530537, -0.23916532, ...,  0.47019705,\n",
       "        -0.97044528, -0.18581873],\n",
       "       [-0.2049723 , -0.37635037,  0.51578683, ...,  0.24819635,\n",
       "        -0.41355443,  0.13478515]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7, dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, Mean loss: 0.0547607652843, Mean accuracy: 0.981999993324\n",
      "epoch : 1, Mean loss: 0.0490360669792, Mean accuracy: 0.983600020409\n",
      "epoch : 2, Mean loss: 0.0510660000145, Mean accuracy: 0.984099984169\n",
      "epoch : 3, Mean loss: 0.042333830148, Mean accuracy: 0.986500024796\n",
      "epoch : 4, Mean loss: 0.0372350290418, Mean accuracy: 0.988300025463\n",
      "epoch : 5, Mean loss: 0.0423946641386, Mean accuracy: 0.985899984837\n",
      "epoch : 6, Mean loss: 0.0409948192537, Mean accuracy: 0.986699998379\n",
      "epoch : 7, Mean loss: 0.0414143800735, Mean accuracy: 0.986299991608\n",
      "epoch : 8, Mean loss: 0.0379548147321, Mean accuracy: 0.986199975014\n",
      "epoch : 9, Mean loss: 0.0414137542248, Mean accuracy: 0.985800027847\n",
      "epoch : 10, Mean loss: 0.0394147112966, Mean accuracy: 0.987500011921\n",
      "epoch : 11, Mean loss: 0.030145181343, Mean accuracy: 0.990400016308\n",
      "epoch : 12, Mean loss: 0.0308239590377, Mean accuracy: 0.990299999714\n",
      "epoch : 13, Mean loss: 0.037976142019, Mean accuracy: 0.988099992275\n",
      "epoch : 14, Mean loss: 0.0375423878431, Mean accuracy: 0.987699985504\n",
      "epoch : 15, Mean loss: 0.0377181023359, Mean accuracy: 0.98710000515\n",
      "epoch : 16, Mean loss: 0.0343645997345, Mean accuracy: 0.98869997263\n",
      "epoch : 17, Mean loss: 0.0381282940507, Mean accuracy: 0.985899984837\n",
      "epoch : 18, Mean loss: 0.0422330126166, Mean accuracy: 0.986299991608\n",
      "epoch : 19, Mean loss: 0.027366457507, Mean accuracy: 0.99169999361\n",
      "epoch : 20, Mean loss: 0.0368894450366, Mean accuracy: 0.988099992275\n",
      "epoch : 21, Mean loss: 0.0303752627224, Mean accuracy: 0.989899992943\n",
      "epoch : 22, Mean loss: 0.0318675450981, Mean accuracy: 0.989499986172\n",
      "epoch : 23, Mean loss: 0.0361401289701, Mean accuracy: 0.987299978733\n",
      "epoch : 24, Mean loss: 0.0294678285718, Mean accuracy: 0.990700006485\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# run\n",
    "xp = model.xp\n",
    "\n",
    "pbar = tqdm(xrange(epochsize))\n",
    "for epoch in pbar:\n",
    "    for batch in train_iter:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        # terminate\n",
    "        if train_iter.is_new_epoch is True:\n",
    "            break\n",
    "\n",
    "    # evaluate model   \n",
    "    sum_loss = 0\n",
    "    sum_acc = 0\n",
    "    test_iter_copy = copy.copy(test_iter)\n",
    "    for test_batch in test_iter_copy:\n",
    "        # data separation\n",
    "        x = xp.asarray([it[0] for it in test_batch], dtype=np.float32)\n",
    "        t = xp.asarray([it[1] for it in test_batch], dtype=np.int32)\n",
    "        # compute grad\n",
    "        loss = model(x, t)\n",
    "        sum_loss += loss.data * len(test_batch)\n",
    "        sum_acc += model.accuracy.data * len(test_batch)\n",
    "    mean_loss = sum_loss / testsize\n",
    "    mean_acc = sum_acc / testsize\n",
    "#     print(''.format(epoch=epoch))\n",
    "    print('epoch : {epoch}, Mean loss: {loss}, Mean accuracy: {acc}'.format(epoch=epoch, loss=mean_loss, acc=mean_acc))\n",
    "    # pbar.set_description('epoch : {epoch}'.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "28b4adbff9404d5dac95b8058bd91253": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
